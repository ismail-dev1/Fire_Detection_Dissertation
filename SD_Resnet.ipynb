{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOU4xPNXxHP5CTCrreYQQwB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismail-dev1/Fire_Detection_Dissertation/blob/main/SD_Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHpHY7a82iru",
        "outputId": "c5e1d604-f064-48cc-f4ae-d0f013f18d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 Torchvision: 0.23.0+cu126\n",
            "CUDA available: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch, torchvision\n",
        "print(\"Torch:\", torch.__version__, \"Torchvision:\", torchvision.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "up = files.upload()  # choose your zip, e.g. fire_dataset.zip\n",
        "zip_name = list(up.keys())[0]\n",
        "\n",
        "!mkdir -p /content/data\n",
        "!unzip -q \"$zip_name\" -d /content/data\n",
        "\n",
        "# If your zip contains the folder fire_dataset/, set this accordingly:\n",
        "DATA_DIR = \"/content/data/fire_dataset\"  # adjust if needed\n",
        "!ls -R \"$DATA_DIR\" | head -n 40\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "cIB0x-X13e0O",
        "outputId": "7602cdeb-feec-443f-af47-5bbf5b0aeea5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a5b93397-3e39-427d-bbae-7c86ec5110f7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a5b93397-3e39-427d-bbae-7c86ec5110f7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fire_dataset.zip to fire_dataset.zip\n",
            "/content/data/fire_dataset:\n",
            "fire\n",
            "no_fire\n",
            "\n",
            "/content/data/fire_dataset/fire:\n",
            "ComfyUI_00001_ 2.png\n",
            "ComfyUI_00001_ copy.png\n",
            "ComfyUI_00001_.png\n",
            "ComfyUI_00002_ 2.png\n",
            "ComfyUI_00002_ copy.png\n",
            "ComfyUI_00002_.png\n",
            "ComfyUI_00003_ 2.png\n",
            "ComfyUI_00003_.png\n",
            "ComfyUI_00004_ 2.png\n",
            "ComfyUI_00004_ copy.png\n",
            "ComfyUI_00004_.png\n",
            "ComfyUI_00005_ 2.png\n",
            "ComfyUI_00005_.png\n",
            "ComfyUI_00006_ 2.png\n",
            "ComfyUI_00006_ copy.png\n",
            "ComfyUI_00006_.png\n",
            "ComfyUI_00007_ 2.png\n",
            "ComfyUI_00007_ copy.png\n",
            "ComfyUI_00007_.png\n",
            "ComfyUI_00008_ 2.png\n",
            "ComfyUI_00008_.png\n",
            "ComfyUI_00009_ 2.png\n",
            "ComfyUI_00009_.png\n",
            "ComfyUI_00010_ 2.png\n",
            "ComfyUI_00010_.png\n",
            "ComfyUI_00011_ 2.png\n",
            "ComfyUI_00011_.png\n",
            "ComfyUI_00012_ 2.png\n",
            "ComfyUI_00012_.png\n",
            "ComfyUI_00013_ 2.png\n",
            "ComfyUI_00013_.png\n",
            "ComfyUI_00014_ 2.png\n",
            "ComfyUI_00014_.png\n",
            "ComfyUI_00015_ 2.png\n",
            "ComfyUI_00015_.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "SRC = DATA_DIR  # fire/ and no_fire/ live directly under SRC\n",
        "DST = \"/content/data_split\"\n",
        "VAL_RATIO = 0.15\n",
        "random.seed(42)\n",
        "\n",
        "classes = [d for d in os.listdir(SRC) if os.path.isdir(os.path.join(SRC,d))]\n",
        "assert set(classes) >= {\"fire\",\"no_fire\"}, f\"Found classes: {classes}\"\n",
        "\n",
        "for split in [\"train\",\"val\"]:\n",
        "    for c in classes:\n",
        "        os.makedirs(os.path.join(DST, split, c), exist_ok=True)\n",
        "\n",
        "by_class = {c: [] for c in classes}\n",
        "for c in classes:\n",
        "    cdir = os.path.join(SRC, c)\n",
        "    for f in sorted(os.listdir(cdir)):\n",
        "        p = os.path.join(cdir, f)\n",
        "        if os.path.isfile(p):\n",
        "            by_class[c].append(p)\n",
        "\n",
        "for c, items in by_class.items():\n",
        "    random.shuffle(items)\n",
        "    n_val = max(1, int(len(items)*VAL_RATIO))\n",
        "    val_items = items[:n_val]\n",
        "    trn_items = items[n_val:]\n",
        "    for p in trn_items:\n",
        "        shutil.copy2(p, os.path.join(DST, \"train\", c, os.path.basename(p)))\n",
        "    for p in val_items:\n",
        "        shutil.copy2(p, os.path.join(DST, \"val\", c, os.path.basename(p)))\n",
        "\n",
        "DATA_DIR = DST  # from now on we use the split dataset\n",
        "print(\"Split done at\", DATA_DIR)\n",
        "!find \"$DATA_DIR\" -maxdepth 2 -type d -print\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjeJBFPo3sDF",
        "outputId": "a0c9558f-0d38-4182-a83d-2e61aae62d99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split done at /content/data_split\n",
            "/content/data_split\n",
            "/content/data_split/train\n",
            "/content/data_split/train/no_fire\n",
            "/content/data_split/train/fire\n",
            "/content/data_split/val\n",
            "/content/data_split/val/no_fire\n",
            "/content/data_split/val/fire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, math, torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet50, ResNet18_Weights, ResNet50_Weights\n",
        "\n",
        "# ==== paths ====\n",
        "USE_DRIVE = True   # set False if you don't want to save to Drive\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/fire_resnet\"\n",
        "else:\n",
        "    SAVE_DIR = \"/content/runs_fire_resnet\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ==== config ====\n",
        "IMG_SIZE     = 224\n",
        "BATCH_SIZE   = 64              # bump up since CUDA is faster; reduce if OOM\n",
        "EPOCHS       = 15\n",
        "LR           = 3e-4\n",
        "ARCH         = \"resnet18\"      # or \"resnet50\"\n",
        "PRETRAINED   = True\n",
        "VAL_SUBDIR   = \"val\"           # expected subfolders train/ and val/\n",
        "TRAIN_SUBDIR = \"train\"\n",
        "MIXED_PREC   = True            # AMP on CUDA\n",
        "\n",
        "# ==== data ====\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "train_dir = os.path.join(DATA_DIR, TRAIN_SUBDIR)\n",
        "val_dir   = os.path.join(DATA_DIR, VAL_SUBDIR)\n",
        "\n",
        "train_ds = datasets.ImageFolder(train_dir, transform=train_tf)\n",
        "val_ds   = datasets.ImageFolder(val_dir,   transform=val_tf)\n",
        "class_to_idx = train_ds.class_to_idx\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "print(\"Classes:\", class_to_idx)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ==== model ====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "if ARCH == \"resnet50\":\n",
        "    model = resnet50(weights=ResNet50_Weights.DEFAULT if PRETRAINED else None)\n",
        "    in_feats = model.fc.in_features\n",
        "else:\n",
        "    model = resnet18(weights=ResNet18_Weights.DEFAULT if PRETRAINED else None)\n",
        "    in_feats = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(in_feats, len(class_to_idx))\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\" and MIXED_PREC))\n",
        "\n",
        "def accuracy(logits, y):\n",
        "    return (logits.argmax(1) == y).float().mean().item()\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    model.train(mode=train)\n",
        "    tot_loss = tot_acc = n = 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            if scaler.is_enabled():\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    out = model(xb)\n",
        "                    loss = criterion(out, yb)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                out = model(xb); loss = criterion(out, yb)\n",
        "                loss.backward(); optimizer.step()\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                out = model(xb); loss = criterion(out, yb)\n",
        "        bs = xb.size(0)\n",
        "        tot_loss += loss.item()*bs\n",
        "        tot_acc  += accuracy(out, yb)*bs\n",
        "        n += bs\n",
        "    return tot_loss/n, tot_acc/n\n",
        "\n",
        "best_val = 0.0\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time()\n",
        "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
        "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
        "    dt = time.time() - t0\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f} | {dt:.1f}s\")\n",
        "\n",
        "    # save per-epoch checkpoint (for resume)\n",
        "    ckpt_epoch_path = os.path.join(SAVE_DIR, f\"ckpt_epoch_{epoch:02d}.pt\")\n",
        "    torch.save({\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"arch\": ARCH,\n",
        "        \"img_size\": IMG_SIZE,\n",
        "        \"class_to_idx\": class_to_idx,\n",
        "        \"norm\": {\"mean\": mean, \"std\": std},\n",
        "        \"epoch\": epoch,\n",
        "        \"val_acc\": va_acc,\n",
        "    }, ckpt_epoch_path)\n",
        "\n",
        "    # save best\n",
        "    if va_acc > best_val:\n",
        "        best_val = va_acc\n",
        "        best_path = os.path.join(SAVE_DIR, \"best_fire_resnet.pt\")\n",
        "        torch.save({\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"arch\": ARCH,\n",
        "            \"img_size\": IMG_SIZE,\n",
        "            \"class_to_idx\": class_to_idx,\n",
        "            \"norm\": {\"mean\": mean, \"std\": std},\n",
        "            \"epoch\": epoch,\n",
        "            \"val_acc\": va_acc,\n",
        "        }, best_path)\n",
        "        with open(os.path.join(SAVE_DIR, \"class_to_idx.json\"), \"w\") as f:\n",
        "            json.dump(class_to_idx, f, indent=2)\n",
        "        print(f\"  Saved new best to {best_path} (val_acc={best_val:.3f})\")\n",
        "\n",
        "print(\"Training finished. Best val_acc:\", best_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNX4WlBjDdSZ",
        "outputId": "07985a2a-8202-4c95-b07c-fcecb0ac611d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Classes: {'fire': 0, 'no_fire': 1}\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 104MB/s]\n",
            "/tmp/ipython-input-785717094.py:75: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\" and MIXED_PREC))\n",
            "/tmp/ipython-input-785717094.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/15 | train 0.4476/0.791 | val 0.7668/0.856 | 39.8s\n",
            "  Saved new best to /content/drive/MyDrive/fire_resnet/best_fire_resnet.pt (val_acc=0.856)\n",
            "Epoch 02/15 | train 0.3181/0.857 | val 0.4480/0.848 | 17.6s\n",
            "Epoch 03/15 | train 0.2562/0.900 | val 0.4279/0.860 | 17.4s\n",
            "  Saved new best to /content/drive/MyDrive/fire_resnet/best_fire_resnet.pt (val_acc=0.860)\n",
            "Epoch 04/15 | train 0.2030/0.915 | val 0.4300/0.856 | 17.4s\n",
            "Epoch 05/15 | train 0.1717/0.934 | val 0.4939/0.868 | 17.4s\n",
            "  Saved new best to /content/drive/MyDrive/fire_resnet/best_fire_resnet.pt (val_acc=0.868)\n",
            "Epoch 06/15 | train 0.1492/0.943 | val 0.4992/0.833 | 17.3s\n",
            "Epoch 07/15 | train 0.1046/0.967 | val 0.6025/0.852 | 17.3s\n",
            "Epoch 08/15 | train 0.0830/0.969 | val 0.6833/0.837 | 17.4s\n",
            "Epoch 09/15 | train 0.1006/0.964 | val 0.6557/0.798 | 17.3s\n",
            "Epoch 10/15 | train 0.0939/0.966 | val 0.6040/0.848 | 17.4s\n",
            "Epoch 11/15 | train 0.0915/0.967 | val 0.5489/0.852 | 17.3s\n",
            "Epoch 12/15 | train 0.0857/0.965 | val 0.4677/0.844 | 17.4s\n",
            "Epoch 13/15 | train 0.0652/0.976 | val 0.5412/0.840 | 17.4s\n",
            "Epoch 14/15 | train 0.0639/0.978 | val 0.6748/0.848 | 17.4s\n",
            "Epoch 15/15 | train 0.0503/0.982 | val 0.7009/0.798 | 17.5s\n",
            "Training finished. Best val_acc: 0.867704280155642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, torch, numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BEST_PATH = \"/content/drive/MyDrive/fire_resnet/best_fire_resnet.pt\"  # adjust if needed\n",
        "DATA_DIR  = \"/content/data_split\"  # or your train/val root\n",
        "\n",
        "# Transforms must match training normalization\n",
        "IMG_SIZE = 224\n",
        "mean = [0.485, 0.456, 0.406]; std = [0.229, 0.224, 0.225]\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "val_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"), transform=val_tf)\n",
        "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "class_to_idx = val_ds.class_to_idx\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "ckpt = torch.load(BEST_PATH, map_location=DEVICE)\n",
        "arch = ckpt.get(\"arch\", \"resnet18\")\n",
        "num_classes = len(ckpt[\"class_to_idx\"])\n",
        "\n",
        "if arch == \"resnet50\":\n",
        "    model = resnet50(num_classes=num_classes)\n",
        "else:\n",
        "    model = resnet18(num_classes=num_classes)\n",
        "model.load_state_dict(ckpt[\"state_dict\"]); model.to(DEVICE).eval()\n",
        "\n",
        "# Gather predictions\n",
        "all_probs, all_true, all_paths = [], [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        logits = model(xb)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        all_probs.append(probs); all_true.append(yb.numpy())\n",
        "        # stash file paths for error analysis\n",
        "        start = len(all_paths)\n",
        "        all_paths.extend([val_ds.samples[start+i][0] for i in range(probs.shape[0])])\n",
        "all_probs = np.concatenate(all_probs, 0)\n",
        "all_true  = np.concatenate(all_true, 0)\n",
        "\n",
        "import csv\n",
        "os.makedirs(\"/content/eval\", exist_ok=True)\n",
        "with open(\"/content/eval/val_predictions.csv\",\"w\",newline=\"\") as fh:\n",
        "    w=csv.writer(fh); w.writerow([\"path\",\"true\",\"pred\",\"p_fire\"])\n",
        "    fire_idx = class_to_idx.get(\"fire\", 1)  # fallback in case\n",
        "    for i in range(len(all_true)):\n",
        "        pred = int(all_probs[i].argmax())\n",
        "        p_fire = float(all_probs[i, fire_idx])\n",
        "        w.writerow([all_paths[i], idx_to_class[all_true[i]], idx_to_class[pred], f\"{p_fire:.4f}\"])\n",
        "print(\"Saved /content/eval/val_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnZ7u97LF9f4",
        "outputId": "25d7fca4-8511-485f-fe3d-872c64f51e52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/eval/val_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n = len(class_to_idx)\n",
        "cm = np.zeros((n,n), dtype=int)\n",
        "pred = all_probs.argmax(1)\n",
        "for t,p in zip(all_true, pred): cm[t,p]+=1\n",
        "print(\"Confusion (rows=true, cols=pred):\\n\", cm)\n",
        "\n",
        "tp = np.diag(cm).astype(float)\n",
        "prec = tp / np.maximum(cm.sum(0), 1)\n",
        "rec  = tp / np.maximum(cm.sum(1), 1)\n",
        "for i in range(n):\n",
        "    print(f\"{idx_to_class[i]:8s}  precision={prec[i]:.3f}  recall={rec[i]:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDX6XTwqF-CX",
        "outputId": "997fde3a-6a8b-4907-b588-a8400b9b5097"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion (rows=true, cols=pred):\n",
            " [[163   9]\n",
            " [ 25  60]]\n",
            "fire      precision=0.867  recall=0.948\n",
            "no_fire   precision=0.870  recall=0.706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(12),\n",
        "    transforms.ColorJitter(0.35,0.35,0.35,0.10),\n",
        "    transforms.RandomGrayscale(p=0.2),           # de-emphasize color shortcuts\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02,0.15), ratio=(0.3,3.3)),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "NVCBb3soF-Q5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RN18 @320 (8-10)epochs\n",
        "ARCH = \"resnet18\"\n",
        "IMG_SIZE = 320\n",
        "BASE_BS = 64         # what worked at 224\n",
        "BATCH_SIZE = max(16, int(BASE_BS * (224/IMG_SIZE)**2))  # ≈32 at 320\n"
      ],
      "metadata": {
        "id": "ehQuZH-_Hd8N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACCUM_STEPS = 2\n",
        "optimizer.zero_grad(set_to_none=True)\n",
        "# Ensure the model is on the correct device\n",
        "model.to(device)\n",
        "for step, (xb, yb) in enumerate(train_loader, 1):\n",
        "    xb, yb = xb.to(device), yb.to(device)\n",
        "    if scaler.is_enabled():\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb) / ACCUM_STEPS\n",
        "        scaler.scale(loss).backward()\n",
        "        if step % ACCUM_STEPS == 0:\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "    else:\n",
        "        out = model(xb); loss = criterion(out, yb) / ACCUM_STEPS\n",
        "        loss.backward()\n",
        "        if step % ACCUM_STEPS == 0:\n",
        "            optimizer.step(); optimizer.zero_grad(set_to_none=True)"
      ],
      "metadata": {
        "id": "0tTIfrESINnb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, torch\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Adjust if you saved elsewhere\n",
        "SAVE_DIR  = \"/content/drive/MyDrive/fire_resnet\"\n",
        "BEST_PATH = os.path.join(SAVE_DIR, \"best_fire_resnet.pt\")\n",
        "\n",
        "# Use the same size you just trained with\n",
        "IMG_SIZE = 320\n",
        "\n",
        "# If DATA_DIR isn't defined in this runtime, set it:\n",
        "try:\n",
        "    DATA_DIR\n",
        "except NameError:\n",
        "    DATA_DIR = \"/content/data_split\"  # change if needed\n",
        "\n",
        "ckpt = torch.load(BEST_PATH, map_location=device)\n",
        "train_cti = ckpt[\"class_to_idx\"]                      # mapping used during training\n",
        "class_names = [c for c,_ in sorted(train_cti.items(), key=lambda kv: kv[1])]\n",
        "norm = ckpt.get(\"norm\", {\"mean\":[0.485,0.456,0.406], \"std\":[0.229,0.224,0.225]})\n",
        "\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(norm[\"mean\"], norm[\"std\"]),\n",
        "])\n",
        "\n",
        "val_dir = os.path.join(DATA_DIR, \"val\")\n",
        "val_ds  = datasets.ImageFolder(val_dir, transform=val_tf)\n",
        "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Rebuild the exact model head\n",
        "arch = ckpt.get(\"arch\",\"resnet18\")\n",
        "num_classes = len(train_cti)\n",
        "if arch == \"resnet50\":\n",
        "    model = resnet50(num_classes=num_classes)\n",
        "else:\n",
        "    model = resnet18(num_classes=num_classes)\n",
        "model.load_state_dict(ckpt[\"state_dict\"])\n",
        "model.to(device).eval()\n",
        "\n",
        "# Run forward pass over val once\n",
        "all_probs = []\n",
        "with torch.no_grad():\n",
        "    for xb, _ in val_loader:\n",
        "        xb = xb.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(xb)\n",
        "            probs = torch.softmax(logits, dim=1).cpu().numpy()  # columns in train_cti order\n",
        "        all_probs.append(probs)\n",
        "all_probs = np.concatenate(all_probs, axis=0)\n",
        "\n",
        "# Ground truth (names) and file paths in loader order\n",
        "all_paths = [p for (p, _) in val_ds.samples]\n",
        "all_true_names = [val_ds.classes[y] for (_, y) in val_ds.samples]\n",
        "y_true_idx = np.array([train_cti[name] for name in all_true_names])  # map to training indices\n"
      ],
      "metadata": {
        "id": "2E6_8HFfIiFy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_idx = all_probs.argmax(1)\n",
        "n = len(class_names)\n",
        "cm = np.zeros((n,n), dtype=int)\n",
        "for t,p in zip(y_true_idx, pred_idx): cm[t,p] += 1\n",
        "\n",
        "print(\"Confusion (rows=true, cols=pred) in training-class order:\", class_names)\n",
        "print(cm)\n",
        "\n",
        "tp = np.diag(cm).astype(float)\n",
        "prec = tp / np.maximum(cm.sum(0), 1)\n",
        "rec  = tp / np.maximum(cm.sum(1), 1)\n",
        "for i, cname in enumerate(class_names):\n",
        "    print(f\"{cname:8s}  precision={prec[i]:.3f}  recall={rec[i]:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsRR8xSTIu3e",
        "outputId": "3060d7f8-976d-4e38-cb97-b981c7f6b9c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion (rows=true, cols=pred) in training-class order: ['fire', 'no_fire']\n",
            "[[157  15]\n",
            " [ 28  57]]\n",
            "fire      precision=0.849  recall=0.913\n",
            "no_fire   precision=0.792  recall=0.671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Picking a different threshold to improve no_fire\n",
        "import numpy as np\n",
        "\n",
        "fire_idx   = train_cti['fire']\n",
        "no_fire_idx= train_cti['no_fire']\n",
        "p_fire = all_probs[:, fire_idx]\n",
        "y_fire = (y_true_idx == fire_idx).astype(int)   # 1=fire, 0=no_fire\n",
        "\n",
        "grid = []\n",
        "for t in np.linspace(0.05, 0.95, 19):\n",
        "    yhat = (p_fire >= t).astype(int)\n",
        "    tp = ((y_fire==1)&(yhat==1)).sum()\n",
        "    fp = ((y_fire==0)&(yhat==1)).sum()\n",
        "    tn = ((y_fire==0)&(yhat==0)).sum()\n",
        "    fn = ((y_fire==1)&(yhat==0)).sum()\n",
        "    prec = tp/max(tp+fp,1); rec=tp/max(tp+fn,1); spec=tn/max(tn+fp,1)  # spec = no_fire recall\n",
        "    f1 = 2*prec*rec/max(prec+rec,1e-9)\n",
        "    grid.append((t, prec, rec, spec, f1, fp, fn))\n",
        "grid = np.array(grid, dtype=object)\n",
        "\n",
        "# choose by your goal\n",
        "t_f1     = float(grid[grid[:,4].argmax(), 0])\n",
        "t_spec80 = float(grid[(grid[:,3] >= 0.80)][0,0]) if (grid[:,3] >= 0.80).any() else 0.5\n",
        "print(\"t_f1:\", round(t_f1,2), \"t_spec80:\", round(t_spec80,2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYCExgqhI2Za",
        "outputId": "6c843db7-b068-4c9c-a497-5414b3792283"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_f1: 0.6 t_spec80: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take the current false positives (true=no_fire, predicted=fire) and fold them into training so the model learns those patterns.\n",
        "\n",
        "import csv, os, shutil\n",
        "FP_DIR = \"/content/hard_negatives\"\n",
        "os.makedirs(FP_DIR, exist_ok=True)\n",
        "\n",
        "with open(\"/content/eval/val_predictions.csv\") as fh:\n",
        "    for i,row in enumerate(csv.DictReader(fh)):\n",
        "        if row[\"true\"]==\"no_fire\" and row[\"pred\"]==\"fire\":\n",
        "            src = row[\"path\"]\n",
        "            if os.path.exists(src):\n",
        "                shutil.copy2(src, os.path.join(FP_DIR, os.path.basename(src)))\n",
        "\n",
        "# copy hard negatives into training/no_fire\n",
        "TR_NOFIRE = os.path.join(DATA_DIR, \"train\", \"no_fire\")\n",
        "for f in os.listdir(FP_DIR):\n",
        "    shutil.copy2(os.path.join(FP_DIR,f), os.path.join(TR_NOFIRE, f\"hn_{f}\"))\n",
        "print(\"Added hard negatives to train/no_fire\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMl_r0YNI2en",
        "outputId": "3d527e65-130d-4446-9cee-b9e642e1dfad"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added hard negatives to train/no_fire\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#retrain ResNet-18 @ 320 with the regularization you used and a small bias toward no_fire\n",
        "# class weights from CURRENT train set\n",
        "import numpy as np, torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "counts = np.bincount([y for _,y in train_ds.samples], minlength=len(train_ds.classes))\n",
        "w_inv = counts.sum() / (len(counts) * counts)  # inverse frequency\n",
        "class_weights = torch.tensor(w_inv, dtype=torch.float, device=device)\n",
        "\n",
        "# upweight hard negatives inside the sampler\n",
        "sample_w = np.ones(len(train_ds.samples), dtype=float)\n",
        "hn_basenames = set([f\"hn_{os.path.basename(p)}\" for p,_ in train_ds.samples])  # names we just added\n",
        "for i,(path,y) in enumerate(train_ds.samples):\n",
        "    if y == train_ds.class_to_idx['no_fire'] and os.path.basename(path) in hn_basenames:\n",
        "        sample_w[i] = 3.0  # emphasize hard negatives\n",
        "\n",
        "sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "\n",
        "# loss + mild head dropout\n",
        "in_feats = model.fc.in_features\n",
        "model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, len(train_ds.classes)))\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\n"
      ],
      "metadata": {
        "id": "ZKWTd56qI2kF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Short retrain (8–10 epochs) + eval + threshold sweep ===\n",
        "import os, json, time, numpy as np\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet50, ResNet18_Weights, ResNet50_Weights\n",
        "\n",
        "# --- paths / config ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA_DIR = globals().get(\"DATA_DIR\", \"/content/data_split\")  # expects train/ and val/ inside\n",
        "SAVE_DIR = \"/content/drive/MyDrive/fire_resnet\"              # change if you like\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "ARCH        = \"resnet18\"   # keep rn18 for this quick pass\n",
        "IMG_SIZE    = 320\n",
        "BASE_BS     = 64           # what worked at 224\n",
        "BATCH_SIZE  = max(16, int(BASE_BS * (224/IMG_SIZE)**2))  # ~32 at 320\n",
        "EPOCHS      = 10\n",
        "PATIENCE    = 4\n",
        "LR          = 3e-4\n",
        "WEIGHT_DEC  = 5e-4\n",
        "PRETRAINED  = True\n",
        "MIXED_PREC  = True\n",
        "\n",
        "# --- data/transforms (augmentation tuned to reduce orange-light FPs) ---\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(12),\n",
        "    transforms.ColorJitter(0.35, 0.35, 0.35, 0.10),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "train_dir = os.path.join(DATA_DIR, \"train\")\n",
        "val_dir   = os.path.join(DATA_DIR, \"val\")\n",
        "train_ds  = datasets.ImageFolder(train_dir, transform=train_tf)\n",
        "val_ds    = datasets.ImageFolder(val_dir,   transform=val_tf)\n",
        "class_to_idx = train_ds.class_to_idx\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "# --- class weights (inverse frequency) + sampler (boost hard negatives if prefixed \"hn_\") ---\n",
        "counts = np.bincount([y for _,y in train_ds.samples], minlength=len(train_ds.classes))\n",
        "inv_freq = counts.sum() / (len(counts) * np.maximum(counts, 1))\n",
        "class_weights_t = torch.tensor(inv_freq, dtype=torch.float, device=device)\n",
        "\n",
        "sample_w = np.array([inv_freq[y] for _,y in train_ds.samples], dtype=np.float32)\n",
        "for i,(p,y) in enumerate(train_ds.samples):\n",
        "    if idx_to_class[y] == 'no_fire' and os.path.basename(p).startswith(\"hn_\"):\n",
        "        sample_w[i] *= 3.0  # extra emphasis on hard negatives\n",
        "sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=max(64, BATCH_SIZE), shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# --- model ---\n",
        "if ARCH == \"resnet50\":\n",
        "    model = resnet50(weights=ResNet50_Weights.DEFAULT if PRETRAINED else None)\n",
        "    in_feats = model.fc.in_features\n",
        "else:\n",
        "    model = resnet18(weights=ResNet18_Weights.DEFAULT if PRETRAINED else None)\n",
        "    in_feats = model.fc.in_features\n",
        "model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, len(class_to_idx)))\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_t, label_smoothing=0.05)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DEC)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda' and MIXED_PREC))\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    model.train(mode=train)\n",
        "    tot_loss = tot_acc = n = 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            if scaler.is_enabled():\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    out = model(xb); loss = criterion(out, yb)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer); scaler.update()\n",
        "            else:\n",
        "                out = model(xb); loss = criterion(out, yb)\n",
        "                loss.backward(); optimizer.step()\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                with torch.amp.autocast('cuda', enabled=scaler.is_enabled()):\n",
        "                    out = model(xb); loss = criterion(out, yb)\n",
        "        bs = xb.size(0)\n",
        "        tot_loss += loss.item()*bs\n",
        "        tot_acc  += (out.argmax(1) == yb).float().mean().item()*bs\n",
        "        n += bs\n",
        "    return tot_loss/n, tot_acc/n\n",
        "\n",
        "# --- train with early stopping, save best ---\n",
        "best_val = 0.0\n",
        "bad_epochs = 0\n",
        "best_path = os.path.join(SAVE_DIR, \"best_fire_resnet.pt\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
        "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f}\")\n",
        "    scheduler.step(va_loss)\n",
        "\n",
        "    # save per-epoch (optional but resilient)\n",
        "    torch.save({\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"arch\": ARCH,\n",
        "        \"img_size\": IMG_SIZE,\n",
        "        \"class_to_idx\": class_to_idx,\n",
        "        \"norm\": {\"mean\": mean, \"std\": std},\n",
        "        \"epoch\": epoch,\n",
        "        \"val_acc\": va_acc,\n",
        "    }, os.path.join(SAVE_DIR, f\"ckpt_epoch_{epoch:02d}.pt\"))\n",
        "\n",
        "    if va_acc > best_val:\n",
        "        best_val = va_acc; bad_epochs = 0\n",
        "        torch.save({\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"arch\": ARCH,\n",
        "            \"img_size\": IMG_SIZE,\n",
        "            \"class_to_idx\": class_to_idx,\n",
        "            \"norm\": {\"mean\": mean, \"std\": std},\n",
        "            \"epoch\": epoch,\n",
        "            \"val_acc\": va_acc,\n",
        "        }, best_path)\n",
        "        with open(os.path.join(SAVE_DIR, \"class_to_idx.json\"), \"w\") as f:\n",
        "            json.dump(class_to_idx, f, indent=2)\n",
        "        print(f\"  Saved new best to {best_path} (val_acc={best_val:.3f})\")\n",
        "    else: # early stopping\n",
        "        bad_epochs += 1\n",
        "        if bad_epochs >= PATIENCE:\n",
        "            print(f\"Early stopping after {bad_epochs} epochs without improvement.\")\n",
        "            break\n",
        "\n",
        "print(\"Training finished. Best val_acc:\", best_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urusuWXFI2mK",
        "outputId": "a7a7fbcc-e65d-48dd-b4c2-ef85bd46e749"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/10 | train 0.5630/0.697 | val 0.5616/0.829\n",
            "  Saved new best to /content/drive/MyDrive/fire_resnet/best_fire_resnet.pt (val_acc=0.829)\n",
            "Epoch 02/10 | train 0.4265/0.795 | val 0.6760/0.743\n",
            "Epoch 03/10 | train 0.3642/0.846 | val 0.4601/0.864\n",
            "  Saved new best to /content/drive/MyDrive/fire_resnet/best_fire_resnet.pt (val_acc=0.864)\n",
            "Epoch 04/10 | train 0.3844/0.826 | val 0.7238/0.728\n",
            "Epoch 05/10 | train 0.3604/0.840 | val 0.4107/0.860\n",
            "Epoch 06/10 | train 0.3092/0.874 | val 0.4576/0.829\n",
            "Epoch 07/10 | train 0.3006/0.872 | val 0.3970/0.872\n",
            "  Saved new best to /content/drive/MyDrive/fire_resnet/best_fire_resnet.pt (val_acc=0.872)\n",
            "Epoch 08/10 | train 0.2818/0.894 | val 0.5436/0.817\n",
            "Epoch 09/10 | train 0.2577/0.914 | val 1.0183/0.669\n",
            "Epoch 10/10 | train 0.2504/0.916 | val 0.4556/0.840\n",
            "Training finished. Best val_acc: 0.8715953307392996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resnet 50 @320 with grad accumulation (8–10 epochs)\n",
        "import os, json, time, numpy as np, torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# paths\n",
        "DATA_DIR = \"/content/data_split\"                       # train/ and val/ inside\n",
        "SAVE_DIR = \"/content/drive/MyDrive/fire_resnet_rn50\"   # keep RN50 runs separate\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# config\n",
        "ARCH        = \"resnet50\"\n",
        "IMG_SIZE    = 320\n",
        "BASE_BS     = 64\n",
        "BATCH_SIZE  = 24                       # safe on T4/L4; adjust if you have more VRAM\n",
        "ACCUM_STEPS = 2                        # effective batch ~= 48\n",
        "EPOCHS      = 10\n",
        "PATIENCE    = 4\n",
        "LR          = 3e-4\n",
        "WEIGHT_DEC  = 5e-4\n",
        "PRETRAINED  = True\n",
        "MIXED_PREC  = True\n",
        "\n",
        "# transforms (same philosophy you used to reduce orange-light FPs)\n",
        "mean = [0.485, 0.456, 0.406]; std = [0.229, 0.224, 0.225]\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(12),\n",
        "    transforms.ColorJitter(0.35,0.35,0.35,0.10),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "    transforms.RandomErasing(p=0.25, scale=(0.02,0.15), ratio=(0.3,3.3)),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR,\"train\"), transform=train_tf)\n",
        "val_ds   = datasets.ImageFolder(os.path.join(DATA_DIR,\"val\"),   transform=val_tf)\n",
        "class_to_idx = train_ds.class_to_idx\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "# inverse-frequency class weights + weighted sampler\n",
        "counts = np.bincount([y for _,y in train_ds.samples], minlength=len(train_ds.classes))\n",
        "inv_freq = counts.sum() / (len(counts) * np.maximum(counts,1))\n",
        "class_weights_t = torch.tensor(inv_freq, dtype=torch.float, device=device)\n",
        "\n",
        "sample_w = np.array([inv_freq[y] for _,y in train_ds.samples], dtype=np.float32)\n",
        "# if you added hard negatives with prefix \"hn_\", boost them:\n",
        "for i,(p,y) in enumerate(train_ds.samples):\n",
        "    if idx_to_class[y]=='no_fire' and os.path.basename(p).startswith(\"hn_\"):\n",
        "        sample_w[i] *= 3.0\n",
        "sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=max(64,BATCH_SIZE), shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# model\n",
        "model = resnet50(weights=ResNet50_Weights.DEFAULT if PRETRAINED else None)\n",
        "in_feats = model.fc.in_features\n",
        "model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, len(class_to_idx)))\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_t, label_smoothing=0.05)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DEC)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda' and MIXED_PREC))\n",
        "\n",
        "def train_or_eval(loader, train=True):\n",
        "    model.train(mode=train)\n",
        "    tot_loss = tot_acc = n = 0\n",
        "    if train:\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "    for step,(xb,yb) in enumerate(loader,1):\n",
        "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "        if train:\n",
        "            if scaler.is_enabled():\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    out = model(xb); loss = criterion(out, yb)/ACCUM_STEPS\n",
        "                scaler.scale(loss).backward()\n",
        "                if step % ACCUM_STEPS == 0:\n",
        "                    scaler.step(optimizer); scaler.update()\n",
        "                    optimizer.zero_grad(set_to_none=True)\n",
        "            else:\n",
        "                out = model(xb); loss = criterion(out, yb)/ACCUM_STEPS\n",
        "                loss.backward()\n",
        "                if step % ACCUM_STEPS == 0:\n",
        "                    optimizer.step(); optimizer.zero_grad(set_to_none=True)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                with torch.amp.autocast('cuda', enabled=scaler.is_enabled()):\n",
        "                    out = model(xb); loss = criterion(out, yb)\n",
        "        bs = xb.size(0)\n",
        "        tot_loss += loss.item()*bs if not train else (loss.item()*bs*ACCUM_STEPS)\n",
        "        tot_acc  += (out.argmax(1)==yb).float().mean().item()*bs\n",
        "        n += bs\n",
        "    return tot_loss/n, tot_acc/n\n",
        "\n",
        "best_val, bad = 0.0, 0\n",
        "best_path = os.path.join(SAVE_DIR, \"best_fire_resnet.pt\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = train_or_eval(train_loader, train=True)\n",
        "    va_loss, va_acc = train_or_eval(val_loader,   train=False)\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f}\")\n",
        "    scheduler.step(va_loss)\n",
        "    torch.save({\"state_dict\":model.state_dict(),\"arch\":\"resnet50\",\"img_size\":IMG_SIZE,\n",
        "                \"class_to_idx\":class_to_idx,\"norm\":{\"mean\":mean,\"std\":std},\n",
        "                \"epoch\":epoch,\"val_acc\":va_acc}, os.path.join(SAVE_DIR,f\"ckpt_epoch_{epoch:02d}.pt\"))\n",
        "    if va_acc > best_val:\n",
        "        best_val, bad = va_acc, 0\n",
        "        torch.save({\"state_dict\":model.state_dict(),\"arch\":\"resnet50\",\"img_size\":IMG_SIZE,\n",
        "                    \"class_to_idx\":class_to_idx,\"norm\":{\"mean\":mean,\"std\":std},\n",
        "                    \"epoch\":epoch,\"val_acc\":va_acc}, best_path)\n",
        "        with open(os.path.join(SAVE_DIR,\"class_to_idx.json\"),\"w\") as f:\n",
        "            json.dump(class_to_idx,f,indent=2)\n",
        "        print(f\"  Saved best → {best_path} (val_acc={best_val:.3f})\")\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad >= PATIENCE:\n",
        "            print(\"Early stopping.\"); break\n",
        "\n",
        "print(\"Best val_acc:\", round(best_val,3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GJx8X_IMyou",
        "outputId": "fcd6be32-e7d8-455b-cc7e-27552d01f670"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 151MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/10 | train 0.4744/0.691 | val 0.4614/0.833\n",
            "  Saved best → /content/drive/MyDrive/fire_resnet_rn50/best_fire_resnet.pt (val_acc=0.833)\n",
            "Epoch 02/10 | train 0.3598/0.850 | val 0.5011/0.802\n",
            "Epoch 03/10 | train 0.3275/0.866 | val 0.4192/0.872\n",
            "  Saved best → /content/drive/MyDrive/fire_resnet_rn50/best_fire_resnet.pt (val_acc=0.872)\n",
            "Epoch 04/10 | train 0.3139/0.877 | val 0.4695/0.837\n",
            "Epoch 05/10 | train 0.2611/0.910 | val 0.5547/0.802\n",
            "Epoch 06/10 | train 0.2543/0.917 | val 0.4104/0.864\n",
            "Epoch 07/10 | train 0.2397/0.932 | val 0.4300/0.875\n",
            "  Saved best → /content/drive/MyDrive/fire_resnet_rn50/best_fire_resnet.pt (val_acc=0.875)\n",
            "Epoch 08/10 | train 0.2264/0.929 | val 0.4350/0.848\n",
            "Epoch 09/10 | train 0.1974/0.957 | val 0.5509/0.821\n",
            "Epoch 10/10 | train 0.1828/0.969 | val 0.4971/0.833\n",
            "Best val_acc: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RN50 eval + threshold\n",
        "import os, json, numpy as np, torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn # Import nn module\n",
        "\n",
        "device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DATA_DIR = \"/content/data_split\"\n",
        "SAVE_DIR = \"/content/drive/MyDrive/fire_resnet_rn50\"\n",
        "BEST     = f\"{SAVE_DIR}/best_fire_resnet.pt\"\n",
        "IMG_SIZE = 320\n",
        "\n",
        "ckpt = torch.load(BEST, map_location=device)\n",
        "cti  = ckpt[\"class_to_idx\"]; itc = {v:k for k,v in cti.items()}\n",
        "norm = ckpt.get(\"norm\", {\"mean\":[0.485,0.456,0.406], \"std\":[0.229,0.224,0.225]})\n",
        "arch = ckpt.get(\"arch\",\"resnet50\")\n",
        "\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.14)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(norm[\"mean\"], norm[\"std\"]),\n",
        "])\n",
        "val_ds = datasets.ImageFolder(os.path.join(DATA_DIR,\"val\"), transform=val_tf)\n",
        "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# rebuild model with the Sequential head\n",
        "num_classes = len(cti)\n",
        "if arch == \"resnet50\":\n",
        "    model = resnet50(weights=None) # Initialize without pretrained weights\n",
        "    in_feats = model.fc.in_features\n",
        "else:\n",
        "    model = resnet18(weights=None) # Initialize without pretrained weights\n",
        "    in_feats = model.fc.in_features\n",
        "\n",
        "# Recreate the Sequential layer with Dropout and Linear\n",
        "model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, num_classes))\n",
        "\n",
        "\n",
        "model.load_state_dict(ckpt[\"state_dict\"]); model.to(device).eval()\n",
        "\n",
        "# collect probs\n",
        "probs = []\n",
        "with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "    for xb,_ in val_loader:\n",
        "        xb = xb.to(device)\n",
        "        logits = model(xb)\n",
        "        probs.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "probs = np.concatenate(probs, 0)\n",
        "\n",
        "# ground truth mapped to training indices\n",
        "y_true = np.array([cti[val_ds.classes[y]] for _,y in val_ds.samples])\n",
        "\n",
        "# confusion @ argmax\n",
        "pred = probs.argmax(1)\n",
        "cm = np.zeros((len(cti),len(cti)), dtype=int)\n",
        "for t,p in zip(y_true, pred): cm[t,p]+=1\n",
        "print(\"Classes:\", [itc[i] for i in range(len(cti))])\n",
        "print(\"Confusion @ argmax:\\n\", cm)\n",
        "\n",
        "# threshold sweep for 'fire'\n",
        "fire_idx = cti[\"fire\"]; nof_idx = cti[\"no_fire\"]\n",
        "p_fire = probs[:, fire_idx]; y_fire = (y_true==fire_idx).astype(int)\n",
        "\n",
        "rows=[]\n",
        "for t in np.linspace(0.05, 0.95, 19):\n",
        "    yhat = (p_fire >= t).astype(int)\n",
        "    tp = ((y_fire==1)&(yhat==1)).sum()\n",
        "    fp = ((y_fire==0)&(yhat==1)).sum()\n",
        "    tn = ((y_fire==0)&(yhat==0)).sum()\n",
        "    fn = ((y_fire==1)&(yhat==0)).sum()\n",
        "    prec = tp/max(tp+fp,1); rec=tp/max(tp+fn,1); spec=tn/max(tn+fp,1)  # spec = no_fire recall\n",
        "    f1 = 2*prec*rec/max(prec+rec,1e-9)\n",
        "    rows.append((t,prec,rec,spec,f1))\n",
        "grid = np.array(rows, dtype=float)\n",
        "\n",
        "t_f1     = grid[grid[:,4].argmax(), 0]\n",
        "t_spec80 = grid[grid[:,3] >= 0.80][0,0] if (grid[:,3] >= 0.80).any() else 0.5\n",
        "print(f\"RN50 thresholds → t_f1={t_f1:.2f}, t_spec80={t_spec80:.2f}\")\n",
        "\n",
        "# confusion @ chosen threshold\n",
        "THRESH = t_spec80\n",
        "pred_th = np.where(p_fire >= THRESH, fire_idx, nof_idx)\n",
        "cm_t = np.zeros_like(cm)\n",
        "for t,p in zip(y_true, pred_th): cm_t[t,p]+=1\n",
        "print(f\"\\nConfusion @ threshold={THRESH:.2f}:\\n\", cm_t)\n",
        "\n",
        "# save deploy meta\n",
        "with open(f\"{SAVE_DIR}/deploy_meta.json\",\"w\") as f:\n",
        "    json.dump({\"threshold_fire\": float(THRESH),\n",
        "               \"img_size\": IMG_SIZE, \"norm\": norm,\n",
        "               \"class_to_idx\": cti, \"arch\": arch}, f, indent=2)\n",
        "print(\"Saved\", f\"{SAVE_DIR}/deploy_meta.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFyiGHnxUijk",
        "outputId": "d6c2f366-aa98-4c78-c495-93c5e8630b01"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['fire', 'no_fire']\n",
            "Confusion @ argmax:\n",
            " [[141  31]\n",
            " [  1  84]]\n",
            "RN50 thresholds → t_f1=0.10, t_spec80=0.10\n",
            "\n",
            "Confusion @ threshold=0.10:\n",
            " [[161  11]\n",
            " [ 11  74]]\n",
            "Saved /content/drive/MyDrive/fire_resnet_rn50/deploy_meta.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare RN18@320 vs RN50@320 with F1- and specificity-driven thresholds\n",
        "import os, json, numpy as np, torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn # Import nn module\n",
        "\n",
        "def eval_model(save_dir, img_size=320):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ckpt = torch.load(f\"{save_dir}/best_fire_resnet.pt\", map_location=device)\n",
        "    cti  = ckpt[\"class_to_idx\"]; itc = {v:k for k,v in cti.items()}\n",
        "    norm = ckpt.get(\"norm\", {\"mean\":[0.485,0.456,0.406], \"std\":[0.229,0.224,0.225]})\n",
        "    arch = ckpt.get(\"arch\",\"resnet18\")\n",
        "\n",
        "    tf = transforms.Compose([\n",
        "        transforms.Resize(int(img_size*1.14)),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(norm[\"mean\"], norm[\"std\"]),\n",
        "    ])\n",
        "    val_ds = datasets.ImageFolder(\"/content/data_split/val\", transform=tf)\n",
        "    loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Initialize model\n",
        "    if arch==\"resnet50\":\n",
        "        model = resnet50(weights=None) # Initialize without pretrained weights\n",
        "        in_feats = model.fc.in_features\n",
        "    else:\n",
        "        model = resnet18(weights=None) # Initialize without pretrained weights\n",
        "        in_feats = model.fc.in_features\n",
        "\n",
        "    # Recreate the Sequential layer with Dropout and Linear\n",
        "    model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, len(cti)))\n",
        "\n",
        "    model.load_state_dict(ckpt[\"state_dict\"]); model.to(device).eval()\n",
        "\n",
        "    probs=[]\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "        for xb,_ in loader:\n",
        "            xb = xb.to(device)\n",
        "            probs.append(torch.softmax(model(xb), dim=1).cpu().numpy())\n",
        "    probs = np.concatenate(probs,0)\n",
        "    y_true = np.array([cti[val_ds.classes[y]] for _,y in val_ds.samples])\n",
        "\n",
        "    fire = cti[\"fire\"]; nof = cti[\"no_fire\"]\n",
        "    p = probs[:, fire]; y = (y_true==fire).astype(int)\n",
        "\n",
        "    # sweep thresholds\n",
        "    def sweep(p,y):\n",
        "        best_f1 = (-1,0)   # (score, thr)\n",
        "        spec80  = None\n",
        "        for t in np.linspace(0.05,0.95,19):\n",
        "            yhat = (p>=t).astype(int)\n",
        "            tp = ((y==1)&(yhat==1)).sum()\n",
        "            fp = ((y==0)&(yhat==1)).sum()\n",
        "            tn = ((y==0)&(yhat==0)).sum()\n",
        "            fn = ((y==1)&(yhat==0)).sum()\n",
        "            prec = tp/max(tp+fp,1); rec = tp/max(tp+fn,1); spec = tn/max(tn+fp,1)\n",
        "            f1 = 2*prec*rec/max(prec+rec,1e-9)\n",
        "            if f1 > best_f1[0]: best_f1 = (f1,t)\n",
        "            if spec80 is None and spec >= 0.80: spec80 = t\n",
        "        return best_f1[1], spec80 if spec80 is not None else 0.5\n",
        "\n",
        "    t_f1, t_spec80 = sweep(p,y)\n",
        "\n",
        "    # metrics @ those thresholds\n",
        "    def metrics_at(t):\n",
        "        pred = np.where(p>=t, fire, nof)\n",
        "        cm = np.zeros((2,2),dtype=int)\n",
        "        for t_,p_ in zip((y_true==fire).astype(int), (pred==fire).astype(int)):\n",
        "            cm[t_,p_] += 1\n",
        "        tp, fp = cm[1,1], cm[0,1]\n",
        "        tn, fn = cm[0,0], cm[1,0]\n",
        "        prec = tp/max(tp+fp,1); rec = tp/max(tp+fn,1); spec = tn/max(tn+fp,1)\n",
        "        f1 = 2*prec*rec/max(prec+rec,1e-9)\n",
        "        return dict(threshold=float(t), precision=float(prec), recall_fire=float(rec),\n",
        "                    recall_no_fire=float(spec), f1=float(f1), cm=cm.tolist())\n",
        "\n",
        "    return {\"dir\": save_dir,\n",
        "            \"t_f1\": metrics_at(t_f1),\n",
        "            \"t_spec80\": metrics_at(t_spec80)}\n",
        "\n",
        "r18 = eval_model(\"/content/drive/MyDrive/fire_resnet\", img_size=320)\n",
        "r50 = eval_model(\"/content/drive/MyDrive/fire_resnet_rn50\", img_size=320)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([\n",
        "    {\"model\":\"RN18@320\",\"mode\":\"t_f1\",**r18[\"t_f1\"]},\n",
        "    {\"model\":\"RN18@320\",\"mode\":\"t_spec80\",**r18[\"t_spec80\"]},\n",
        "    {\"model\":\"RN50@320\",\"mode\":\"t_f1\",**r50[\"t_f1\"]},\n",
        "    {\"model\":\"RN50@320\",\"mode\":\"t_spec80\",**r50[\"t_spec80\"]},\n",
        "])\n",
        "print(df[[\"model\",\"mode\",\"threshold\",\"f1\",\"precision\",\"recall_fire\",\"recall_no_fire\"]].to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j7Czj8PU4OP",
        "outputId": "b7997e99-f5b6-4d68-aa3f-eb1316dfe8ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   model     mode  threshold       f1  precision  recall_fire  recall_no_fire\n",
            "RN18@320     t_f1       0.25 0.923077   0.939759     0.906977        0.882353\n",
            "RN18@320 t_spec80       0.20 0.919540   0.909091     0.930233        0.811765\n",
            "RN50@320     t_f1       0.10 0.936047   0.936047     0.936047        0.870588\n",
            "RN50@320 t_spec80       0.10 0.936047   0.936047     0.936047        0.870588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Pick which run you want to plot ---\n",
        "# RN18:\n",
        "RUN_DIR = \"/content/drive/MyDrive/fire_resnet\"\n",
        "\n",
        "# RN50:\n",
        "#RUN_DIR = \"/content/drive/MyDrive/fire_resnet_rn50\"\n",
        "\n",
        "# --- Common config ---\n",
        "DATA_DIR = \"/content/data_split\"   # has train/ and val/\n",
        "IMG_SIZE = 320\n",
        "\n",
        "import os, json, glob, math, numpy as np, matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "STAMP   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUT_DIR = os.path.join(RUN_DIR, f\"figs_{STAMP}\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "BEST_PATH = os.path.join(RUN_DIR, \"best_fire_resnet.pt\")\n",
        "META_PATH = os.path.join(RUN_DIR, \"deploy_meta.json\")\n",
        "\n",
        "if not os.path.exists(BEST_PATH):\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {BEST_PATH}\")\n",
        "print(\"Using RUN_DIR:\", RUN_DIR)\n",
        "print(\"Figures will be saved to:\", OUT_DIR)\n",
        "\n",
        "def savefig_multi(basename, tight=True):\n",
        "    if tight: plt.tight_layout()\n",
        "    png = os.path.join(OUT_DIR, f\"{basename}.png\")\n",
        "    pdf = os.path.join(OUT_DIR, f\"{basename}.pdf\")\n",
        "    svg = os.path.join(OUT_DIR, f\"{basename}.svg\")\n",
        "    plt.savefig(png, dpi=300); plt.savefig(pdf); plt.savefig(svg)\n",
        "    print(\"Saved:\", png, \"and .pdf/.svg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5g4ppIVXoP7",
        "outputId": "ea6a9203-f458-4356-9625-f1eae94d86dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using RUN_DIR: /content/drive/MyDrive/fire_resnet\n",
            "Figures will be saved to: /content/drive/MyDrive/fire_resnet/figs_20250909_164905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# PICK ONE:\n",
        "# RUN_DIR = \"/content/drive/MyDrive/fire_resnet\"        # RN18\n",
        "RUN_DIR = \"/content/drive/MyDrive/fire_resnet_rn50\"     # RN50\n",
        "\n",
        "assert RUN_DIR.startswith(\"/content/drive/\"), \"RUN_DIR must be a Drive path\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr4R9ql7XoRd",
        "outputId": "ebde65f2-ee28-4cc0-a1ee-41990f4c1339"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "\n",
        "STAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUT_DIR = os.path.join(RUN_DIR, f\"figs_{STAMP}\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n",
        "\n",
        "# sanity check: can we write here?\n",
        "test_txt = os.path.join(OUT_DIR, \"write_check.txt\")\n",
        "with open(test_txt, \"w\") as f:\n",
        "    f.write(\"ok\")\n",
        "print(\"Wrote:\", test_txt, \"size:\", os.path.getsize(test_txt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pantgDpXoTB",
        "outputId": "01abffe0-8721-46eb-faef-1a71fac0d350"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUT_DIR: /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165222\n",
            "Wrote: /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165222/write_check.txt size: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def savefig_multi(fig, basename):\n",
        "    \"\"\"Save a matplotlib Figure to PNG/PDF/SVG in OUT_DIR.\"\"\"\n",
        "    for ext in (\"png\", \"pdf\", \"svg\"):\n",
        "        path = os.path.join(OUT_DIR, f\"{basename}.{ext}\")\n",
        "        fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
        "        if not os.path.exists(path):\n",
        "            raise RuntimeError(f\"Failed to save {path}\")\n",
        "    plt.close(fig)  # free memory\n",
        "    print(f\"Saved {basename} → {OUT_DIR}\")\n",
        "\n",
        "def save_current(basename):\n",
        "    savefig_multi(plt.gcf(), basename)\n"
      ],
      "metadata": {
        "id": "Ww954v_-XoUq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all graphs for a run (RN18 or RN50) to Google Drive\n",
        "!pip -q install scikit-learn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, json, glob, math, time, numpy as np, matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import torch, torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, confusion_matrix\n",
        "\n",
        "#  which trained runs to export figures for\n",
        "RUN_DIRS = [\n",
        "  \"/content/drive/MyDrive/fire_resnet_rn50\",  # RN50\n",
        "  # \"/content/drive/MyDrive/fire_resnet\",     # RN18 (uncomment if you want both)\n",
        "]\n",
        "\n",
        "DATA_DIR = \"/content/data_split\"  # contains train/ and val/\n",
        "\n",
        "def savefig_multi(fig, out_dir, basename):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    for ext in (\"png\", \"pdf\", \"svg\"):\n",
        "        path = os.path.join(out_dir, f\"{basename}.{ext}\")\n",
        "        fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"Saved {basename} -> {out_dir}\")\n",
        "\n",
        "def build_model(arch, n_classes):\n",
        "    # Initialize base model without the default classifier\n",
        "    if arch==\"resnet50\":\n",
        "        model = resnet50(weights=None) # Initialize without pretrained weights\n",
        "        in_feats = model.fc.in_features\n",
        "    else:\n",
        "        model = resnet18(weights=None) # Initialize without pretrained weights\n",
        "        in_feats = model.fc.in_features\n",
        "\n",
        "    # Recreate the Sequential layer with Dropout and Linear as used in training\n",
        "    model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_feats, n_classes))\n",
        "    return model\n",
        "\n",
        "\n",
        "for RUN_DIR in RUN_DIRS:\n",
        "    assert RUN_DIR.startswith(\"/content/drive/\"), f\"RUN_DIR must be on Drive, got: {RUN_DIR}\"\n",
        "    BEST_PATH = os.path.join(RUN_DIR, \"best_fire_resnet.pt\")\n",
        "    META_PATH = os.path.join(RUN_DIR, \"deploy_meta.json\")\n",
        "    assert os.path.exists(BEST_PATH), f\"Missing checkpoint: {BEST_PATH}\"\n",
        "\n",
        "    STAMP   = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    OUT_DIR = os.path.join(RUN_DIR, f\"figs_{STAMP}\")\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "    print(\"\\n=== Exporting figures for:\", RUN_DIR, \"→\", OUT_DIR)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ckpt   = torch.load(BEST_PATH, map_location=device)\n",
        "\n",
        "    class_to_idx = ckpt[\"class_to_idx\"]\n",
        "    idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "    arch  = ckpt.get(\"arch\", \"resnet18\")\n",
        "    IMG_SIZE = int(ckpt.get(\"img_size\", 320))\n",
        "\n",
        "    # normalization + chosen threshold (if present)\n",
        "    norm = {\"mean\":[0.485,0.456,0.406], \"std\":[0.229,0.224,0.225]}\n",
        "    THRESHOLD = 0.5\n",
        "    if os.path.exists(META_PATH):\n",
        "        meta = json.load(open(META_PATH))\n",
        "        norm = meta.get(\"norm\", norm)\n",
        "        # Check if 'threshold_fire' exists before accessing it\n",
        "        if 'threshold_fire' in meta:\n",
        "            THRESHOLD = float(meta[\"threshold_fire\"])\n",
        "\n",
        "    # data / loader\n",
        "    val_tf = transforms.Compose([\n",
        "        transforms.Resize(int(IMG_SIZE*1.14)),\n",
        "        transforms.CenterCrop(IMG_SIZE),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(norm[\"mean\"], norm[\"std\"]),\n",
        "    ])\n",
        "    val_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"), transform=val_tf)\n",
        "    val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # model + preds\n",
        "    model = build_model(arch, len(class_to_idx))\n",
        "    model.load_state_dict(ckpt[\"state_dict\"])\n",
        "    model.to(device).eval()\n",
        "\n",
        "    probs_list, y_list = [], []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            probs_list.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "            y_list.append(yb.numpy())\n",
        "    all_probs = np.concatenate(probs_list, 0)\n",
        "    y_true    = np.concatenate(y_list, 0)\n",
        "    paths     = [p for (p, _) in val_ds.samples]\n",
        "\n",
        "    # save per-image predictions CSV\n",
        "    import csv\n",
        "    csv_path = os.path.join(OUT_DIR, \"val_predictions.csv\")\n",
        "    with open(csv_path, \"w\", newline=\"\") as fh:\n",
        "        w = csv.writer(fh); w.writerow([\"path\",\"true\",\"p_fire\",\"p_no_fire\"])\n",
        "        for pth, yi, prob in zip(paths, y_true, all_probs):\n",
        "            w.writerow([pth, val_ds.classes[yi],\n",
        "                        f\"{prob[class_to_idx['fire']]:.6f}\",\n",
        "                        f\"{prob[class_to_idx['no_fire']]:.6f}\"])\n",
        "    print(\"Saved:\", csv_path)\n",
        "\n",
        "    #    confusion matrices\n",
        "    # argmax\n",
        "    y_pred_arg = all_probs.argmax(1)\n",
        "    cm_arg = confusion_matrix(y_true, y_pred_arg,\n",
        "                              labels=[class_to_idx['fire'], class_to_idx['no_fire']])\n",
        "\n",
        "    fig = plt.figure(figsize=(4.6,4))\n",
        "    plt.imshow(cm_arg, interpolation='nearest')\n",
        "    plt.xticks([0,1], ['fire','no_fire']); plt.yticks([0,1], ['fire','no_fire'])\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion – Argmax\")\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, str(cm_arg[i,j]), ha=\"center\", va=\"center\")\n",
        "    savefig_multi(fig, OUT_DIR, \"confusion_argmax\")\n",
        "\n",
        "    # thresholded\n",
        "    p_fire = all_probs[:, class_to_idx['fire']]\n",
        "    y_pred_thr = np.where(p_fire >= THRESHOLD, class_to_idx['fire'], class_to_idx['no_fire'])\n",
        "    cm_thr = confusion_matrix(y_true, y_pred_thr,\n",
        "                              labels=[class_to_idx['fire'], class_to_idx['no_fire']])\n",
        "\n",
        "    fig = plt.figure(figsize=(4.6,4))\n",
        "    plt.imshow(cm_thr, interpolation='nearest')\n",
        "    plt.xticks([0,1], ['fire','no_fire']); plt.yticks([0,1], ['fire','no_fire'])\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(f\"Confusion – Threshold τ={THRESHOLD:.2f}\")\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, str(cm_thr[i,j]), ha=\"center\", va=\"center\")\n",
        "    savefig_multi(fig, OUT_DIR, \"confusion_thresholded\")\n",
        "\n",
        "    #  ROC & PR curves\n",
        "    y_bin = (y_true == class_to_idx['fire']).astype(int)\n",
        "\n",
        "    from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "    fpr, tpr, _ = roc_curve(y_bin, p_fire)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    fig = plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr, lw=2, label=f\"AUC={roc_auc:.3f}\")\n",
        "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
        "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(\"ROC (fire vs no_fire)\")\n",
        "    plt.legend()\n",
        "    savefig_multi(fig, OUT_DIR, \"roc_curve\")\n",
        "\n",
        "    prec, rec, _ = precision_recall_curve(y_bin, p_fire)\n",
        "    ap = average_precision_score(y_bin, p_fire)\n",
        "    fig = plt.figure(figsize=(5,4))\n",
        "    plt.plot(rec, prec, lw=2, label=f\"AP={ap:.3f}\")\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision–Recall (fire)\")\n",
        "    plt.legend()\n",
        "    savefig_multi(fig, OUT_DIR, \"pr_curve\")\n",
        "\n",
        "    # threshold sweeps\n",
        "    ts = np.linspace(0.05, 0.95, 37)\n",
        "    rows = []\n",
        "    for t in ts:\n",
        "        yhat = (p_fire >= t).astype(int)\n",
        "        tp = ((y_bin==1)&(yhat==1)).sum()\n",
        "        fp = ((y_bin==0)&(yhat==1)).sum()\n",
        "        tn = ((y_bin==0)&(yhat==0)).sum()\n",
        "        fn = ((y_bin==1)&(yhat==0)).sum()\n",
        "        precision = tp / max(tp+fp,1)\n",
        "        recall    = tp / max(tp+fn,1)\n",
        "        spec      = tn / max(tn+fp,1)  # no_fire recall\n",
        "        f1        = 2*precision*recall / max(precision+recall,1e-9)\n",
        "        rows.append((t, precision, recall, spec, f1))\n",
        "    rows = np.array(rows)\n",
        "\n",
        "    fig = plt.figure(figsize=(6,4))\n",
        "    plt.plot(rows[:,0], rows[:,1], label=\"Precision\")\n",
        "    plt.plot(rows[:,0], rows[:,2], label=\"Recall (fire)\")\n",
        "    plt.plot(rows[:,0], rows[:,3], label=\"Recall (no_fire)\")\n",
        "    plt.axvline(THRESHOLD, linestyle=\"--\", label=f\"τ={THRESHOLD:.2f}\")\n",
        "    plt.xlabel(\"Threshold τ on p(fire)\"); plt.ylabel(\"Score\"); plt.title(\"Precision/Recall vs τ\")\n",
        "    plt.legend()\n",
        "    savefig_multi(fig, OUT_DIR, \"threshold_sweep_precision_recall\")\n",
        "\n",
        "    fig = plt.figure(figsize=(6,4))\n",
        "    plt.plot(rows[:,0], rows[:,4], label=\"F1 (fire)\")\n",
        "    plt.axvline(THRESHOLD, linestyle=\"--\", label=f\"τ={THRESHOLD:.2f}\")\n",
        "    plt.xlabel(\"Threshold τ on p(fire)\"); plt.ylabel(\"F1\"); plt.title(\"F1 vs τ\")\n",
        "    plt.legend()\n",
        "    savefig_multi(fig, OUT_DIR, \"threshold_sweep_f1\")\n",
        "\n",
        "    # --- training curves from saved checkpoints ---\n",
        "    ckpts = sorted(glob.glob(os.path.join(RUN_DIR, \"ckpt_epoch_*.pt\")))\n",
        "    if len(ckpts) > 0:\n",
        "        epochs, val_accs, val_losses = [], [], []\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # build a loader we can reuse for loss recompute\n",
        "        # (reuse val_loader created above)\n",
        "        for pth in ckpts:\n",
        "            c = torch.load(pth, map_location=device)\n",
        "            ep = int(os.path.basename(pth).split(\"_\")[-1].split(\".\")[0])\n",
        "            epochs.append(ep)\n",
        "            val_accs.append(float(c.get(\"val_acc\", np.nan)))\n",
        "\n",
        "            # build model with correct head for loss recompute\n",
        "            m = build_model(c.get(\"arch\", arch), len(class_to_idx))\n",
        "            m.load_state_dict(c[\"state_dict\"]); m.to(device).eval()\n",
        "\n",
        "            tot, n = 0.0, 0\n",
        "            with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                for xb, yb in val_loader:\n",
        "                    xb, yb = xb.to(device), yb.to(device)\n",
        "                    logits = m(xb)\n",
        "                    loss = criterion(logits, yb)\n",
        "                    tot += float(loss.item()) * xb.size(0)\n",
        "                    n   += xb.size(0)\n",
        "            val_losses.append(tot / max(n,1))\n",
        "\n",
        "        # val acc plot\n",
        "        fig = plt.figure(figsize=(6,4))\n",
        "        plt.plot(epochs, val_accs, marker=\"o\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Val Accuracy\"); plt.title(f\"Validation Accuracy over Epochs ({arch})\")\n",
        "        savefig_multi(fig, OUT_DIR, \"training_val_accuracy\")\n",
        "\n",
        "        # val loss plot\n",
        "        fig = plt.figure(figsize=(6,4))\n",
        "        plt.plot(epochs, val_losses, marker=\"o\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Val Loss\"); plt.title(f\"Validation Loss over Epochs ({arch})\")\n",
        "        savefig_multi(fig, OUT_DIR, \"training_val_loss\")\n",
        "    else:\n",
        "        print(\"No ckpt_epoch_*.pt files found; skipping training curves.\")\n",
        "\n",
        "    # list outputs\n",
        "    print(\"\\nFiles saved to:\", OUT_DIR)\n",
        "    !ls -lh \"$OUT_DIR\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAyGdJ5daQe0",
        "outputId": "f1f22286-8559-4ae3-ed46-d06f040c51d1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "=== Exporting figures for: /content/drive/MyDrive/fire_resnet_rn50 → /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved: /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910/val_predictions.csv\n",
            "Saved confusion_argmax -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved confusion_thresholded -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved roc_curve -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved pr_curve -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved threshold_sweep_precision_recall -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved threshold_sweep_f1 -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved training_val_accuracy -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "Saved training_val_loss -> /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "\n",
            "Files saved to: /content/drive/MyDrive/fire_resnet_rn50/figs_20250909_165910\n",
            "total 995K\n",
            "-rw------- 1 root root  13K Sep  9 16:59 confusion_argmax.pdf\n",
            "-rw------- 1 root root  38K Sep  9 16:59 confusion_argmax.png\n",
            "-rw------- 1 root root  27K Sep  9 16:59 confusion_argmax.svg\n",
            "-rw------- 1 root root  12K Sep  9 16:59 confusion_thresholded.pdf\n",
            "-rw------- 1 root root  39K Sep  9 16:59 confusion_thresholded.png\n",
            "-rw------- 1 root root  26K Sep  9 16:59 confusion_thresholded.svg\n",
            "-rw------- 1 root root  13K Sep  9 16:59 pr_curve.pdf\n",
            "-rw------- 1 root root  66K Sep  9 16:59 pr_curve.png\n",
            "-rw------- 1 root root  26K Sep  9 16:59 pr_curve.svg\n",
            "-rw------- 1 root root  13K Sep  9 16:59 roc_curve.pdf\n",
            "-rw------- 1 root root  83K Sep  9 16:59 roc_curve.png\n",
            "-rw------- 1 root root  28K Sep  9 16:59 roc_curve.svg\n",
            "-rw------- 1 root root  13K Sep  9 16:59 threshold_sweep_f1.pdf\n",
            "-rw------- 1 root root  71K Sep  9 16:59 threshold_sweep_f1.png\n",
            "-rw------- 1 root root  24K Sep  9 16:59 threshold_sweep_f1.svg\n",
            "-rw------- 1 root root  15K Sep  9 16:59 threshold_sweep_precision_recall.pdf\n",
            "-rw------- 1 root root 108K Sep  9 16:59 threshold_sweep_precision_recall.png\n",
            "-rw------- 1 root root  35K Sep  9 16:59 threshold_sweep_precision_recall.svg\n",
            "-rw------- 1 root root  13K Sep  9 16:59 training_val_accuracy.pdf\n",
            "-rw------- 1 root root 129K Sep  9 16:59 training_val_accuracy.png\n",
            "-rw------- 1 root root  28K Sep  9 16:59 training_val_accuracy.svg\n",
            "-rw------- 1 root root  13K Sep  9 16:59 training_val_loss.pdf\n",
            "-rw------- 1 root root 122K Sep  9 16:59 training_val_loss.png\n",
            "-rw------- 1 root root  27K Sep  9 16:59 training_val_loss.svg\n",
            "-rw------- 1 root root  20K Sep  9 16:59 val_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChRrqmShzwtS",
        "outputId": "a9abc6a6-910f-4715-c6d0-5fa877ee64e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "CUDA available: True | device: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# Colab: runtime -> GPU first\n",
        "import torch, platform, os, sys, subprocess, json\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"CUDA available:\", torch.cuda.is_available(), \"| device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "\n",
        "!pip -q install matplotlib pandas scikit-learn tqdm opencv-python-headless torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, glob, shutil, zipfile\n",
        "\n",
        "# >>> CHANGE THIS if your zip has a different name or path\n",
        "ZIP_GLOB = \"/content/drive/MyDrive/D-Fire.zip\"   # looks anywhere under MyDrive\n",
        "matches = glob.glob(ZIP_GLOB, recursive=True)\n",
        "assert matches, f\"No zip found matching {ZIP_GLOB}\"\n",
        "ZIP_PATH = matches[0]\n",
        "print(\"Using ZIP:\", ZIP_PATH)\n",
        "\n",
        "# Unzip to /content/DFire (fresh)\n",
        "DST_ROOT = \"/content/DFire\"\n",
        "if os.path.exists(DST_ROOT):\n",
        "    shutil.rmtree(DST_ROOT)\n",
        "os.makedirs(DST_ROOT, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH) as z:\n",
        "    z.extractall(DST_ROOT)\n",
        "\n",
        "print(\"Unzipped to:\", DST_ROOT)\n",
        "!ls -R /content/DFire | head -n 200\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRLMALBf1H3A",
        "outputId": "98108fae-8cb8-4244-9405-3cb2b191745b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using ZIP: /content/drive/MyDrive/D-Fire.zip\n",
            "Unzipped to: /content/DFire\n",
            "/content/DFire:\n",
            "test\n",
            "train\n",
            "\n",
            "/content/DFire/test:\n",
            "images\n",
            "labels\n",
            "\n",
            "/content/DFire/test/images:\n",
            "AoF06723.jpg\n",
            "AoF06724.jpg\n",
            "AoF06725.jpg\n",
            "AoF06726.jpg\n",
            "AoF06727.jpg\n",
            "AoF06728.jpg\n",
            "AoF06729.jpg\n",
            "AoF06730.jpg\n",
            "AoF06731.jpg\n",
            "AoF06732.jpg\n",
            "AoF06733.jpg\n",
            "AoF06734.jpg\n",
            "AoF06735.jpg\n",
            "AoF06736.jpg\n",
            "AoF06737.jpg\n",
            "AoF06738.jpg\n",
            "AoF06739.jpg\n",
            "AoF06740.jpg\n",
            "AoF06741.jpg\n",
            "AoF06742.jpg\n",
            "AoF06743.jpg\n",
            "AoF06744.jpg\n",
            "AoF06745.jpg\n",
            "AoF06746.jpg\n",
            "AoF06747.jpg\n",
            "AoF06748.jpg\n",
            "AoF06749.jpg\n",
            "AoF06750.jpg\n",
            "AoF06751.jpg\n",
            "AoF06752.jpg\n",
            "AoF06753.jpg\n",
            "AoF06754.jpg\n",
            "AoF06755.jpg\n",
            "AoF06756.jpg\n",
            "AoF06757.jpg\n",
            "AoF06758.jpg\n",
            "AoF06759.jpg\n",
            "AoF06760.jpg\n",
            "AoF06761.jpg\n",
            "AoF06762.jpg\n",
            "AoF06763.jpg\n",
            "AoF06764.jpg\n",
            "AoF06765.jpg\n",
            "AoF06766.jpg\n",
            "AoF06767.jpg\n",
            "AoF06768.jpg\n",
            "AoF06769.jpg\n",
            "AoF06770.jpg\n",
            "AoF06771.jpg\n",
            "AoF06772.jpg\n",
            "AoF06773.jpg\n",
            "AoF06774.jpg\n",
            "AoF06775.jpg\n",
            "AoF06776.jpg\n",
            "AoF06777.jpg\n",
            "AoF06778.jpg\n",
            "AoF06779.jpg\n",
            "AoF06780.jpg\n",
            "AoF06781.jpg\n",
            "AoF06782.jpg\n",
            "AoF06783.jpg\n",
            "AoF06784.jpg\n",
            "AoF06785.jpg\n",
            "AoF06786.jpg\n",
            "AoF06787.jpg\n",
            "AoF06788.jpg\n",
            "AoF06789.jpg\n",
            "AoF06790.jpg\n",
            "AoF06791.jpg\n",
            "AoF06792.jpg\n",
            "AoF06793.jpg\n",
            "AoF06794.jpg\n",
            "AoF06795.jpg\n",
            "AoF06796.jpg\n",
            "AoF06797.jpg\n",
            "AoF06798.jpg\n",
            "AoF06799.jpg\n",
            "AoF06800.jpg\n",
            "AoF06801.jpg\n",
            "AoF06802.jpg\n",
            "AoF06803.jpg\n",
            "AoF06804.jpg\n",
            "AoF06805.jpg\n",
            "AoF06806.jpg\n",
            "AoF06807.jpg\n",
            "AoF06808.jpg\n",
            "AoF06809.jpg\n",
            "AoF06810.jpg\n",
            "AoF06811.jpg\n",
            "AoF06812.jpg\n",
            "AoF06813.jpg\n",
            "AoF06814.jpg\n",
            "AoF06815.jpg\n",
            "AoF06816.jpg\n",
            "AoF06817.jpg\n",
            "AoF06818.jpg\n",
            "AoF06819.jpg\n",
            "AoF06820.jpg\n",
            "AoF06821.jpg\n",
            "AoF06822.jpg\n",
            "AoF06823.jpg\n",
            "AoF06824.jpg\n",
            "AoF06825.jpg\n",
            "AoF06826.jpg\n",
            "AoF06827.jpg\n",
            "AoF06828.jpg\n",
            "AoF06829.jpg\n",
            "AoF06830.jpg\n",
            "AoF06831.jpg\n",
            "AoF06832.jpg\n",
            "AoF06833.jpg\n",
            "AoF06834.jpg\n",
            "AoF06835.jpg\n",
            "AoF06836.jpg\n",
            "AoF06837.jpg\n",
            "AoF06838.jpg\n",
            "AoF06839.jpg\n",
            "AoF06840.jpg\n",
            "AoF06841.jpg\n",
            "AoF06842.jpg\n",
            "AoF06843.jpg\n",
            "AoF06844.jpg\n",
            "AoF06845.jpg\n",
            "AoF06846.jpg\n",
            "AoF06847.jpg\n",
            "AoF06848.jpg\n",
            "AoF06849.jpg\n",
            "AoF06850.jpg\n",
            "AoF06851.jpg\n",
            "AoF06852.jpg\n",
            "AoF06853.jpg\n",
            "AoF06854.jpg\n",
            "AoF06855.jpg\n",
            "AoF06856.jpg\n",
            "AoF06857.jpg\n",
            "AoF06858.jpg\n",
            "AoF06859.jpg\n",
            "AoF06860.jpg\n",
            "AoF06861.jpg\n",
            "AoF06862.jpg\n",
            "AoF06863.jpg\n",
            "AoF06864.jpg\n",
            "AoF06865.jpg\n",
            "AoF06866.jpg\n",
            "AoF06867.jpg\n",
            "AoF06868.jpg\n",
            "AoF06869.jpg\n",
            "AoF06870.jpg\n",
            "AoF06871.jpg\n",
            "AoF06872.jpg\n",
            "AoF06873.jpg\n",
            "AoF06874.jpg\n",
            "AoF06875.jpg\n",
            "AoF06876.jpg\n",
            "AoF06877.jpg\n",
            "AoF06878.jpg\n",
            "AoF06879.jpg\n",
            "AoF06880.jpg\n",
            "AoF06881.jpg\n",
            "AoF06882.jpg\n",
            "AoF06883.jpg\n",
            "AoF06884.jpg\n",
            "AoF06885.jpg\n",
            "AoF06886.jpg\n",
            "AoF06887.jpg\n",
            "AoF06888.jpg\n",
            "AoF06889.jpg\n",
            "AoF06890.jpg\n",
            "AoF06891.jpg\n",
            "AoF06892.jpg\n",
            "AoF06893.jpg\n",
            "AoF06894.jpg\n",
            "AoF06895.jpg\n",
            "AoF06896.jpg\n",
            "AoF06897.jpg\n",
            "AoF06898.jpg\n",
            "AoF06899.jpg\n",
            "AoF06900.jpg\n",
            "AoF06901.jpg\n",
            "AoF06902.jpg\n",
            "AoF06903.jpg\n",
            "AoF06904.jpg\n",
            "AoF06905.jpg\n",
            "AoF06906.jpg\n",
            "AoF06907.jpg\n",
            "AoF06908.jpg\n",
            "AoF06909.jpg\n",
            "AoF06910.jpg\n",
            "AoF06911.jpg\n",
            "AoF06912.jpg\n",
            "AoF06913.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "def find_dfire_root(root=\"/content/DFire\"):\n",
        "    # Look for .../train/images and .../test/images\n",
        "    train_imgs = glob.glob(os.path.join(root, \"**/train/images\"), recursive=True)\n",
        "    test_imgs  = glob.glob(os.path.join(root, \"**/test/images\"),  recursive=True)\n",
        "    cands = set(os.path.dirname(os.path.dirname(p)) for p in train_imgs) & set(os.path.dirname(os.path.dirname(p)) for p in test_imgs)\n",
        "    assert cands, \"Could not find train/images and test/images inside the unzipped folder.\"\n",
        "    # Pick the shortest path as the likely root\n",
        "    return sorted(cands, key=len)[0]\n",
        "\n",
        "DATA_SRC = find_dfire_root(\"/content/DFire\")\n",
        "WORKDIR  = \"/content/drive/MyDrive/dfire_colab\"\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "\n",
        "print(\"DATA_SRC =\", DATA_SRC)\n",
        "print(\"Expected structure:\")\n",
        "print(os.path.exists(os.path.join(DATA_SRC, \"train\", \"images\")), \"train/images\")\n",
        "print(os.path.exists(os.path.join(DATA_SRC, \"train\", \"labels\")), \"train/labels\")\n",
        "print(os.path.exists(os.path.join(DATA_SRC, \"test\", \"images\")),  \"test/images\")\n",
        "print(os.path.exists(os.path.join(DATA_SRC, \"test\", \"labels\")),  \"test/labels\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYYKBRxp1ueZ",
        "outputId": "ca344255-f4c2-4518-e20b-e909d0473957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_SRC = /content/DFire\n",
            "Expected structure:\n",
            "True train/images\n",
            "True train/labels\n",
            "True test/images\n",
            "True test/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, sys\n",
        "print(\"CUDA available:\", torch.cuda.is_available(),\n",
        "      \"| device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "!pip -q install matplotlib pandas scikit-learn tqdm opencv-python-headless torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61R4aent1v9Z",
        "outputId": "ca8a30b7-622b-4566-91b3-0f82444a1e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True | device: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumes:\n",
        "# DATA_SRC points to folder with: train/images, train/labels, test/images, test/labels\n",
        "# WORKDIR is where outputs will be saved (e.g., \"/content/drive/MyDrive/dfire_colab\")\n",
        "\n",
        "import os, glob, random, shutil\n",
        "from pathlib import Path\n",
        "random.seed(42)\n",
        "\n",
        "def collect_images(root):\n",
        "    imgs=[]\n",
        "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.webp\"):\n",
        "        imgs += glob.glob(os.path.join(root, \"**\", ext), recursive=True)\n",
        "    return imgs\n",
        "\n",
        "def yolo_positive_stems(lbl_dir):\n",
        "    pos=set()\n",
        "    for p in glob.glob(os.path.join(lbl_dir, \"**/*.txt\"), recursive=True):\n",
        "        with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    pos.add(Path(p).stem)\n",
        "                    break\n",
        "    return pos\n",
        "\n",
        "def copy_to_class_folder(files, pos_stems, out_split_root):\n",
        "    os.makedirs(os.path.join(out_split_root, \"fire\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(out_split_root, \"nonfire\"), exist_ok=True)\n",
        "    kept=0\n",
        "    for im in files:\n",
        "        stem = Path(im).stem\n",
        "        cls = \"fire\" if stem in pos_stems else \"nonfire\"\n",
        "        dst = os.path.join(out_split_root, cls, os.path.basename(im))\n",
        "        if not os.path.exists(dst):\n",
        "            shutil.copy2(im, dst); kept+=1\n",
        "    return kept\n",
        "\n",
        "SRC_TRAIN_IMG = os.path.join(DATA_SRC, \"train\", \"images\")\n",
        "SRC_TRAIN_LBL = os.path.join(DATA_SRC, \"train\", \"labels\")\n",
        "SRC_TEST_IMG  = os.path.join(DATA_SRC, \"test\", \"images\")\n",
        "SRC_TEST_LBL  = os.path.join(DATA_SRC, \"test\", \"labels\")\n",
        "\n",
        "OUT_ROOT = os.path.join(WORKDIR, \"dfire_cls\")\n",
        "for s in [\"train\",\"val\",\"test\"]:\n",
        "    for c in [\"fire\",\"nonfire\"]:\n",
        "        os.makedirs(os.path.join(OUT_ROOT, s, c), exist_ok=True)\n",
        "\n",
        "train_imgs = collect_images(SRC_TRAIN_IMG)\n",
        "random.shuffle(train_imgs)\n",
        "n = len(train_imgs); n_val = max(1, int(0.15*n))\n",
        "train_part, val_part = train_imgs[n_val:], train_imgs[:n_val]\n",
        "\n",
        "train_pos = yolo_positive_stems(SRC_TRAIN_LBL)\n",
        "_ = copy_to_class_folder(train_part, train_pos, os.path.join(OUT_ROOT, \"train\"))\n",
        "_ = copy_to_class_folder(val_part,   train_pos, os.path.join(OUT_ROOT, \"val\"))\n",
        "\n",
        "test_imgs = collect_images(SRC_TEST_IMG)\n",
        "test_pos  = yolo_positive_stems(SRC_TEST_LBL)  # ok if empty\n",
        "_ = copy_to_class_folder(test_imgs, test_pos, os.path.join(OUT_ROOT, \"test\"))\n",
        "\n",
        "def count_dir(d): return sum(1 for _ in glob.iglob(os.path.join(d, \"*\")))\n",
        "for s in [\"train\",\"val\",\"test\"]:\n",
        "    for c in [\"fire\",\"nonfire\"]:\n",
        "        print(f\"{s}/{c}:\", count_dir(os.path.join(OUT_ROOT, s, c)))\n",
        "print(\"ImageFolder ready at:\", OUT_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omv2e6RG57AQ",
        "outputId": "86527ae7-f011-4abb-ae59-853723ca4ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/fire: 7985\n",
            "train/nonfire: 6653\n",
            "val/fire: 1403\n",
            "val/nonfire: 1180\n",
            "test/fire: 2301\n",
            "test/nonfire: 2005\n",
            "ImageFolder ready at: /content/drive/MyDrive/dfire_colab/dfire_cls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs and GPU check\n",
        "import torch, sys, os, json, numpy as np, matplotlib.pyplot as plt\n",
        "print(\"CUDA available:\", torch.cuda.is_available(),\n",
        "      \"| device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "!pip -q install torchvision scikit-learn tqdm pandas opencv-python-headless\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             roc_auc_score, average_precision_score,\n",
        "                             precision_recall_curve, roc_curve, auc)\n",
        "\n",
        "DATA_ROOT = os.path.join(WORKDIR, \"dfire_cls\")\n",
        "EXP_DIR   = os.path.join(WORKDIR, \"exp_resnet18\")\n",
        "os.makedirs(EXP_DIR, exist_ok=True)\n",
        "\n",
        "def get_loaders(root, img_size=224, batch=64, workers=2):\n",
        "    mean=[0.485,0.456,0.406]; std=[0.229,0.224,0.225]\n",
        "    tf_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(img_size, scale=(0.7,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "        transforms.ToTensor(), transforms.Normalize(mean,std),\n",
        "    ])\n",
        "    tf_eval = transforms.Compose([\n",
        "        transforms.Resize(int(img_size*1.15)),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(), transforms.Normalize(mean,std),\n",
        "    ])\n",
        "    tr = datasets.ImageFolder(os.path.join(root,\"train\"), tf_train)\n",
        "    va = datasets.ImageFolder(os.path.join(root,\"val\"),   tf_eval)\n",
        "    te = datasets.ImageFolder(os.path.join(root,\"test\"),  tf_eval)\n",
        "\n",
        "    ys=[y for _,y in tr.samples]\n",
        "    class_counts = np.bincount(ys, minlength=2)\n",
        "    weights = torch.tensor(class_counts.sum()/np.maximum(class_counts,1), dtype=torch.float32)\n",
        "\n",
        "    tr_loader = DataLoader(tr, batch_size=batch, shuffle=True,  num_workers=workers, pin_memory=True)\n",
        "    va_loader = DataLoader(va, batch_size=batch, shuffle=False, num_workers=workers, pin_memory=True)\n",
        "    te_loader = DataLoader(te, batch_size=batch, shuffle=False, num_workers=workers, pin_memory=True)\n",
        "    return tr_loader, va_loader, te_loader, weights\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tr, va, te, class_w = get_loaders(DATA_ROOT, img_size=224, batch=64, workers=2)\n",
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w.to(device))\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    logits_list=[]; y_list=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(device)\n",
        "            logits = model(x)\n",
        "            logits_list.append(logits.cpu()); y_list.append(y)\n",
        "    logits = torch.cat(logits_list); y = torch.cat(y_list).numpy()\n",
        "    probs = logits.softmax(1)[:,1].numpy()\n",
        "    preds = (probs>=0.5).astype(int)\n",
        "    acc = (preds==y).mean()\n",
        "    cm = confusion_matrix(y, preds, labels=[0,1])\n",
        "    try:\n",
        "        auroc = roc_auc_score(y, probs); aupr = average_precision_score(y, probs)\n",
        "    except ValueError:\n",
        "        auroc, aupr = float(\"nan\"), float(\"nan\")\n",
        "    report = classification_report(y, preds, target_names=[\"nonfire\",\"fire\"], digits=4, zero_division=0)\n",
        "    return {\"acc\":acc,\"auroc\":auroc,\"aupr\":aupr,\"cm\":cm,\"y\":y,\"probs\":probs,\"report\":report}\n",
        "\n",
        "best, wait, patience = -1.0, 0, 5\n",
        "for ep in range(1, 21):  # up to 20 epochs\n",
        "    model.train(); running=0.0\n",
        "    for x,y in tr:\n",
        "        x,y=x.to(device), y.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "        running += loss.item()*x.size(0)\n",
        "    train_loss = running/len(tr.dataset)\n",
        "\n",
        "    val = evaluate(va)\n",
        "    score = (val[\"auroc\"] if not np.isnan(val[\"auroc\"]) else val[\"acc\"])\n",
        "    print(f\"Epoch {ep:02d} | train_loss={train_loss:.4f} | val_acc={val['acc']:.4f} | val_auroc={val['auroc']:.4f}\")\n",
        "    torch.save(model.state_dict(), os.path.join(EXP_DIR,\"last.pt\"))\n",
        "    if score > best:\n",
        "        best=score; wait=0\n",
        "        torch.save(model.state_dict(), os.path.join(EXP_DIR,\"best.pt\"))\n",
        "        with open(os.path.join(EXP_DIR,\"val_report.txt\"),\"w\") as f: f.write(val[\"report\"])\n",
        "    else:\n",
        "        wait+=1\n",
        "        if wait>=patience:\n",
        "            print(\"Early stopping.\"); break\n",
        "\n",
        "# Test + artifacts\n",
        "model.load_state_dict(torch.load(os.path.join(EXP_DIR,\"best.pt\"), map_location=device))\n",
        "test = evaluate(te)\n",
        "\n",
        "with open(os.path.join(EXP_DIR,\"test_report.txt\"),\"w\") as f:\n",
        "    f.write(test[\"report\"]); f.write(f\"\\nACC={test['acc']:.4f} AUROC={test['auroc']:.4f} AUPR={test['aupr']:.4f}\\n\")\n",
        "with open(os.path.join(EXP_DIR,\"test_metrics.json\"),\"w\") as f:\n",
        "    json.dump({k: (float(v) if isinstance(v,(int,float,np.floating)) else None)\n",
        "               for k,v in test.items() if k in [\"acc\",\"auroc\",\"aupr\"]}, f, indent=2)\n",
        "\n",
        "# Confusion matrix\n",
        "plt.figure(figsize=(3.2,3.2))\n",
        "plt.imshow(test[\"cm\"])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i,str(test[\"cm\"][i,j]),ha=\"center\",va=\"center\")\n",
        "plt.xticks([0,1],[\"nonfire\",\"fire\"]); plt.yticks([0,1],[\"nonfire\",\"fire\"])\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout()\n",
        "plt.savefig(os.path.join(EXP_DIR,\"cm_test.png\"), dpi=200); plt.close()\n",
        "\n",
        "# PR & ROC\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score\n",
        "p,r,_ = precision_recall_curve(test[\"y\"], test[\"probs\"])\n",
        "ap = average_precision_score(test[\"y\"], test[\"probs\"])\n",
        "plt.figure(); plt.step(r,p,where=\"post\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(f\"PR curve (AP={ap:.3f})\"); plt.tight_layout(); plt.savefig(os.path.join(EXP_DIR,\"curves_test_pr.png\"), dpi=200); plt.close()\n",
        "\n",
        "fpr,tpr,_ = roc_curve(test[\"y\"], test[\"probs\"])\n",
        "aucv = auc(fpr,tpr)\n",
        "plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC curve (AUC={aucv:.3f})\")\n",
        "plt.tight_layout(); plt.savefig(os.path.join(EXP_DIR,\"curves_test_roc.png\"), dpi=200); plt.close()\n",
        "\n",
        "print(\"Done. Artifacts saved to:\", EXP_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4hBSHxC57DC",
        "outputId": "cdbf1d13-209d-4b88-928d-2d8628b86e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True | device: NVIDIA A100-SXM4-40GB\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 228MB/s]\n",
            "/tmp/ipython-input-3256477181.py:53: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss=0.4346 | val_acc=0.7522 | val_auroc=0.8472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | train_loss=0.2954 | val_acc=0.8107 | val_auroc=0.9003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | train_loss=0.2331 | val_acc=0.8068 | val_auroc=0.9112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | train_loss=0.1974 | val_acc=0.8277 | val_auroc=0.9268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | train_loss=0.1655 | val_acc=0.8208 | val_auroc=0.9019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | train_loss=0.1546 | val_acc=0.8289 | val_auroc=0.9207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 07 | train_loss=0.1362 | val_acc=0.8060 | val_auroc=0.9209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 08 | train_loss=0.1280 | val_acc=0.8513 | val_auroc=0.9405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 09 | train_loss=0.1143 | val_acc=0.8200 | val_auroc=0.9102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | train_loss=0.1036 | val_acc=0.8149 | val_auroc=0.9118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | train_loss=0.1020 | val_acc=0.8355 | val_auroc=0.9315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | train_loss=0.0913 | val_acc=0.7998 | val_auroc=0.8959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3256477181.py:81: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 | train_loss=0.0860 | val_acc=0.8455 | val_auroc=0.9327\n",
            "Early stopping.\n",
            "Done. Artifacts saved to: /content/drive/MyDrive/dfire_colab/exp_resnet18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses WORKDIR/dfire_cls and WORKDIR/exp_resnet18 from earlier cells\n",
        "import os, json, numpy as np, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                             average_precision_score, precision_recall_curve, roc_curve, auc)\n",
        "\n",
        "DATA_ROOT = os.path.join(WORKDIR, \"dfire_cls\")\n",
        "EXP_DIR   = os.path.join(WORKDIR, \"exp_resnet18\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Eval transforms must match training eval pipeline (Resize->CenterCrop->Normalize for 224)\n",
        "tf_eval = transforms.Compose([\n",
        "    transforms.Resize(257),  # ~1.15 * 224\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "te_ds = datasets.ImageFolder(os.path.join(DATA_ROOT, \"test\"), tf_eval)\n",
        "te_loader = DataLoader(te_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "model = models.resnet18(weights=None)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model.load_state_dict(torch.load(os.path.join(EXP_DIR, \"best.pt\"), map_location=device))\n",
        "model.to(device).eval()\n",
        "\n",
        "logits_list=[]; y_list=[]\n",
        "with torch.no_grad():\n",
        "    for x,y in te_loader:\n",
        "        x = x.to(device)\n",
        "        logits_list.append(model(x).cpu()); y_list.append(y)\n",
        "logits = torch.cat(logits_list); y = torch.cat(y_list).numpy()\n",
        "probs  = logits.softmax(1)[:,1].numpy()\n",
        "preds  = (probs >= 0.5).astype(int)\n",
        "\n",
        "acc = (preds==y).mean()\n",
        "cm  = confusion_matrix(y, preds, labels=[0,1])\n",
        "auroc = roc_auc_score(y, probs)\n",
        "aupr  = average_precision_score(y, probs)\n",
        "print(f\"TEST  acc={acc:.4f}  AUROC={auroc:.4f}  AUPR={aupr:.4f}\")\n",
        "\n",
        "# Save reports & metrics\n",
        "with open(os.path.join(EXP_DIR,\"test_report.txt\"),\"w\") as f:\n",
        "    f.write(classification_report(y, preds, target_names=[\"nonfire\",\"fire\"], digits=4, zero_division=0))\n",
        "    f.write(f\"\\nACC={acc:.4f} AUROC={auroc:.4f} AUPR={aupr:.4f}\\n\")\n",
        "with open(os.path.join(EXP_DIR,\"test_metrics.json\"),\"w\") as f:\n",
        "    json.dump({\"acc\":float(acc),\"auroc\":float(auroc),\"aupr\":float(aupr)}, f, indent=2)\n",
        "\n",
        "# Confusion matrix\n",
        "plt.figure(figsize=(3.2,3.2))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i,str(cm[i,j]),ha=\"center\",va=\"center\")\n",
        "plt.xticks([0,1],[\"nonfire\",\"fire\"]); plt.yticks([0,1],[\"nonfire\",\"fire\"])\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout()\n",
        "plt.savefig(os.path.join(EXP_DIR,\"cm_test.png\"), dpi=200); plt.close()\n",
        "\n",
        "# PR & ROC\n",
        "p,r,_ = precision_recall_curve(y, probs)\n",
        "ap = average_precision_score(y, probs)\n",
        "plt.figure(); plt.step(r,p,where=\"post\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(f\"PR curve (AP={ap:.3f})\"); plt.tight_layout(); plt.savefig(os.path.join(EXP_DIR,\"curves_test_pr.png\"), dpi=200); plt.close()\n",
        "\n",
        "fpr,tpr,_ = roc_curve(y, probs)\n",
        "aucv = auc(fpr,tpr)\n",
        "plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC curve (AUC={aucv:.3f})\")\n",
        "plt.tight_layout(); plt.savefig(os.path.join(EXP_DIR,\"curves_test_roc.png\"), dpi=200); plt.close()\n",
        "\n",
        "print(\"Saved artifacts to:\", EXP_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPV1OAbe57Fh",
        "outputId": "c79f276c-82e8-4ef3-93af-d86ca117b79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST  acc=0.8409  AUROC=0.9303  AUPR=0.9175\n",
            "Saved artifacts to: /content/drive/MyDrive/dfire_colab/exp_resnet18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/drive/MyDrive/dfire_colab/exp_resnet18\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyuTVjlu57Hk",
        "outputId": "c3bf6196-195c-4858-fba6-e8fa0e0150af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 86M\n",
            "-rw------- 1 root root 43M Sep  9 19:49 best.pt\n",
            "-rw------- 1 root root 18K Sep  9 20:03 cm_test.png\n",
            "-rw------- 1 root root 46K Sep  9 20:03 curves_test_pr.png\n",
            "-rw------- 1 root root 55K Sep  9 20:03 curves_test_roc.png\n",
            "-rw------- 1 root root 43M Sep  9 20:01 last.pt\n",
            "-rw------- 1 root root  92 Sep  9 20:03 test_metrics.json\n",
            "-rw------- 1 root root 363 Sep  9 20:03 test_report.txt\n",
            "-rw------- 1 root root 326 Sep  9 19:49 val_report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ResNet-50 @ 384 on D-Fire ===\n",
        "import os, json, numpy as np, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
        "\n",
        "DATA_ROOT = os.path.join(WORKDIR, \"dfire_cls\")\n",
        "EXP_DIR   = os.path.join(WORKDIR, \"exp_resnet50_384\")\n",
        "IMG_SIZE  = 384\n",
        "BATCH     = 80\n",
        "EPOCHS    = 20\n",
        "PATIENCE  = 5\n",
        "\n",
        "os.makedirs(EXP_DIR, exist_ok=True)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "use_cuda = (device == \"cuda\")\n",
        "\n",
        "def get_loaders(root, img_size=384, batch=64, workers=2):\n",
        "    mean=[0.485,0.456,0.406]; std=[0.229,0.224,0.225]\n",
        "    tf_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(img_size, scale=(0.7,1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "        transforms.ToTensor(), transforms.Normalize(mean,std),\n",
        "    ])\n",
        "    tf_eval = transforms.Compose([\n",
        "        transforms.Resize(int(img_size*1.15)),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(), transforms.Normalize(mean,std),\n",
        "    ])\n",
        "    tr = datasets.ImageFolder(os.path.join(root,\"train\"), tf_train)\n",
        "    va = datasets.ImageFolder(os.path.join(root,\"val\"),   tf_eval)\n",
        "    te = datasets.ImageFolder(os.path.join(root,\"test\"),  tf_eval)\n",
        "\n",
        "    ys=[y for _,y in tr.samples]\n",
        "    cc = np.bincount(ys, minlength=2)\n",
        "    weights = torch.tensor(cc.sum()/np.maximum(cc,1), dtype=torch.float32)\n",
        "\n",
        "    tr_loader = DataLoader(tr, batch_size=batch, shuffle=True,  num_workers=workers, pin_memory=True)\n",
        "    va_loader = DataLoader(va, batch_size=batch, shuffle=False, num_workers=workers, pin_memory=True)\n",
        "    te_loader = DataLoader(te, batch_size=batch, shuffle=False, num_workers=workers, pin_memory=True)\n",
        "    return tr_loader, va_loader, te_loader, weights, tf_eval\n",
        "\n",
        "tr, va, te, class_w, tf_eval = get_loaders(DATA_ROOT, IMG_SIZE, BATCH, workers=2)\n",
        "\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_w.to(device))\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "scaler = (torch.amp.GradScaler(\"cuda\") if use_cuda else None)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    logits_list=[]; y_list=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(device)\n",
        "            logits = model(x)\n",
        "            logits_list.append(logits.cpu()); y_list.append(y)\n",
        "    logits = torch.cat(logits_list); y = torch.cat(y_list).numpy()\n",
        "    probs = logits.softmax(1)[:,1].numpy()\n",
        "    preds = (probs>=0.5).astype(int)\n",
        "    acc = (preds==y).mean()\n",
        "    try:\n",
        "        auroc = roc_auc_score(y, probs); aupr = average_precision_score(y, probs)\n",
        "    except ValueError:\n",
        "        auroc, aupr = float(\"nan\"), float(\"nan\")\n",
        "    return {\"acc\":acc,\"auroc\":auroc,\"aupr\":aupr}\n",
        "\n",
        "best, wait = -1.0, 0\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train(); running=0.0\n",
        "    for x,y in tr:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast(\"cuda\", enabled=use_cuda):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "        else:\n",
        "            loss.backward(); opt.step()\n",
        "        running += loss.item()*x.size(0)\n",
        "    tr_loss = running/len(tr.dataset)\n",
        "    val = evaluate(va)\n",
        "    score = (val[\"auroc\"] if not np.isnan(val[\"auroc\"]) else val[\"acc\"])\n",
        "    print(f\"Epoch {ep:02d} | train_loss={tr_loss:.4f} | val_acc={val['acc']:.4f} | val_auroc={val['auroc']:.4f}\")\n",
        "    torch.save(model.state_dict(), os.path.join(EXP_DIR,\"last.pt\"))\n",
        "    if score > best:\n",
        "        best = score; wait = 0\n",
        "        torch.save(model.state_dict(), os.path.join(EXP_DIR,\"best.pt\"))\n",
        "        with open(os.path.join(EXP_DIR,\"val_metrics.json\"),\"w\") as f:\n",
        "            json.dump(val, f, indent=2)\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= PATIENCE:\n",
        "            print(\"Early stopping.\"); break\n",
        "\n",
        "# Test evaluation + plots\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc\n",
        "\n",
        "def test_and_plot(exp_dir, img_size=IMG_SIZE):\n",
        "    # reload with eval transform at the same size\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.Resize(int(img_size*1.15)),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    te_ds = datasets.ImageFolder(os.path.join(DATA_ROOT,\"test\"), eval_tf)\n",
        "    te_loader = DataLoader(te_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    m = models.resnet50(weights=None); m.fc = nn.Linear(m.fc.in_features, 2)\n",
        "    m.load_state_dict(torch.load(os.path.join(exp_dir,\"best.pt\"), map_location=device))\n",
        "    m = m.to(device).eval()\n",
        "\n",
        "    logits_list=[]; y_list=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in te_loader:\n",
        "            x = x.to(device)\n",
        "            logits_list.append(m(x).cpu()); y_list.append(y)\n",
        "    logits = torch.cat(logits_list); y = torch.cat(y_list).numpy()\n",
        "    probs = logits.softmax(1)[:,1].numpy()\n",
        "    preds = (probs>=0.5).astype(int)\n",
        "\n",
        "    acc  = (preds==y).mean()\n",
        "    auroc= roc_auc_score(y, probs)\n",
        "    aupr = average_precision_score(y, probs)\n",
        "    cm   = confusion_matrix(y, preds, labels=[0,1])\n",
        "    print(f\"TEST  acc={acc:.4f}  AUROC={auroc:.4f}  AUPR={aupr:.4f}\")\n",
        "\n",
        "    # save\n",
        "    with open(os.path.join(exp_dir,\"test_report.txt\"),\"w\") as f:\n",
        "        from sklearn.metrics import classification_report\n",
        "        f.write(classification_report(y, preds, target_names=[\"nonfire\",\"fire\"], digits=4, zero_division=0))\n",
        "        f.write(f\"\\nACC={acc:.4f} AUROC={auroc:.4f} AUPR={aupr:.4f}\\n\")\n",
        "    with open(os.path.join(exp_dir,\"test_metrics.json\"),\"w\") as f:\n",
        "        json.dump({\"acc\":float(acc),\"auroc\":float(auroc),\"aupr\":float(aupr)}, f, indent=2)\n",
        "\n",
        "    # plots\n",
        "    plt.figure(figsize=(3.2,3.2)); plt.imshow(cm, cmap=\"Blues\")\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j,i,str(cm[i,j]),ha=\"center\",va=\"center\")\n",
        "    plt.xticks([0,1],[\"nonfire\",\"fire\"]); plt.yticks([0,1],[\"nonfire\",\"fire\"])\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(exp_dir,\"cm_test.png\"), dpi=200); plt.close()\n",
        "\n",
        "    p,r,_ = precision_recall_curve(y, probs)\n",
        "    ap = average_precision_score(y, probs)\n",
        "    plt.figure(); plt.step(r,p,where=\"post\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"PR curve (AP={ap:.3f})\"); plt.tight_layout(); plt.savefig(os.path.join(exp_dir,\"curves_test_pr.png\"), dpi=200); plt.close()\n",
        "\n",
        "    fpr,tpr,_ = roc_curve(y, probs)\n",
        "    aucv = auc(fpr,tpr)\n",
        "    plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC curve (AUC={aucv:.3f})\")\n",
        "    plt.tight_layout(); plt.savefig(os.path.join(exp_dir,\"curves_test_roc.png\"), dpi=200); plt.close()\n",
        "\n",
        "test_and_plot(EXP_DIR, IMG_SIZE)\n",
        "print(\"Saved to:\", EXP_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "Ovo7ncCs57Ja",
        "outputId": "b20d4e1e-efcc-4a92-bb08-beaa83eec731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 221MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss=0.3898 | val_acc=0.8014 | val_auroc=0.8743\n",
            "Epoch 02 | train_loss=0.2433 | val_acc=0.8033 | val_auroc=0.8836\n",
            "Epoch 03 | train_loss=0.1924 | val_acc=0.8386 | val_auroc=0.9115\n",
            "Epoch 04 | train_loss=0.1605 | val_acc=0.7960 | val_auroc=0.9282\n",
            "Epoch 05 | train_loss=0.1422 | val_acc=0.8277 | val_auroc=0.9164\n",
            "Epoch 06 | train_loss=0.1249 | val_acc=0.7611 | val_auroc=0.8833\n",
            "Epoch 07 | train_loss=0.1180 | val_acc=0.8451 | val_auroc=0.9265\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3096320245.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate exp_resnet50_384 on test\n",
        "import os, json, numpy as np, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "\n",
        "EXP_DIR   = os.path.join(WORKDIR, \"exp_resnet50_384\")\n",
        "DATA_ROOT = os.path.join(WORKDIR, \"dfire_cls\")\n",
        "IMG_SIZE  = 384\n",
        "device    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# test loader @ 384\n",
        "tf_eval = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.15)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "te_ds = datasets.ImageFolder(os.path.join(DATA_ROOT, \"test\"), tf_eval)\n",
        "te_loader = DataLoader(te_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# load best checkpoint\n",
        "model = models.resnet50(weights=None); model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model.load_state_dict(torch.load(os.path.join(EXP_DIR,\"best.pt\"), map_location=device))\n",
        "model = model.to(device).eval()\n",
        "\n",
        "# forward\n",
        "logits_list=[]; y_list=[]\n",
        "with torch.no_grad():\n",
        "    for x,y in te_loader:\n",
        "        x = x.to(device)\n",
        "        logits_list.append(model(x).cpu()); y_list.append(y)\n",
        "logits = torch.cat(logits_list); y = torch.cat(y_list).numpy()\n",
        "probs  = logits.softmax(1)[:,1].numpy()\n",
        "preds  = (probs >= 0.5).astype(int)\n",
        "\n",
        "# metrics\n",
        "acc  = (preds==y).mean()\n",
        "auroc= roc_auc_score(y, probs)\n",
        "aupr = average_precision_score(y, probs)\n",
        "cm   = confusion_matrix(y, preds, labels=[0,1])\n",
        "print(f\"TEST  acc={acc:.4f}  AUROC={auroc:.4f}  AUPR={aupr:.4f}\")\n",
        "\n",
        "# save reports/plots\n",
        "with open(os.path.join(EXP_DIR,\"test_report.txt\"),\"w\") as f:\n",
        "    f.write(classification_report(y, preds, target_names=[\"nonfire\",\"fire\"], digits=4, zero_division=0))\n",
        "    f.write(f\"\\nACC={acc:.4f} AUROC={auroc:.4f} AUPR={aupr:.4f}\\n\")\n",
        "with open(os.path.join(EXP_DIR,\"test_metrics.json\"),\"w\") as f:\n",
        "    json.dump({\"acc\":float(acc),\"auroc\":float(auroc),\"aupr\":float(aupr)}, f, indent=2)\n",
        "\n",
        "plt.figure(figsize=(3.2,3.2)); plt.imshow(cm, cmap=\"Blues\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i,str(cm[i,j]),ha=\"center\",va=\"center\")\n",
        "plt.xticks([0,1],[\"nonfire\",\"fire\"]); plt.yticks([0,1],[\"nonfire\",\"fire\"])\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout()\n",
        "plt.savefig(os.path.join(EXP_DIR,\"cm_test.png\"), dpi=200); plt.close()\n",
        "\n",
        "p,r,_ = precision_recall_curve(y, probs)\n",
        "ap = average_precision_score(y, probs)\n",
        "plt.figure(); plt.step(r,p,where=\"post\"); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(f\"PR curve (AP={ap:.3f})\"); plt.tight_layout(); plt.savefig(os.path.join(EXP_DIR,\"curves_test_pr.png\"), dpi=200); plt.close()\n",
        "\n",
        "fpr,tpr,_ = roc_curve(y, probs); aucv = auc(fpr,tpr)\n",
        "plt.figure(); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC curve (AUC={aucv:.3f})\")\n",
        "plt.tight_layout(); plt.savefig(os.path.join(EXP_DIR,\"curves_test_roc.png\"), dpi=200); plt.close()\n",
        "\n",
        "print(\"Saved artifacts to:\", EXP_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkH3fXU0Nwy-",
        "outputId": "24c7852f-77ca-4cd1-f922-7480fe35c896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST  acc=0.7959  AUROC=0.9125  AUPR=0.8821\n",
            "Saved artifacts to: /content/drive/MyDrive/dfire_colab/exp_resnet50_384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose threshold on VAL for ~90% recall, apply to TEST\n",
        "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "# Assuming DATA_ROOT, EXP_DIR, IMG_SIZE, device, model are defined in previous cells\n",
        "\n",
        "# build val loader @ 384\n",
        "tf_eval = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.15)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "va_ds = datasets.ImageFolder(os.path.join(DATA_ROOT, \"val\"), tf_eval)\n",
        "va_loader = DataLoader(va_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# get val probs\n",
        "val_probs=[]; val_y=[]\n",
        "with torch.no_grad():\n",
        "    for x,y_true in va_loader:\n",
        "        x=x.to(device)\n",
        "        val_probs.append(model(x).softmax(1)[:,1].cpu().numpy())\n",
        "        val_y.append(y_true.numpy())\n",
        "\n",
        "val_probs = np.concatenate(val_probs); val_y = np.concatenate(val_y)\n",
        "\n",
        "p,r,t = precision_recall_curve(val_y, val_probs)\n",
        "target_recall = 0.90\n",
        "# Find the threshold that gives the closest recall to target_recall\n",
        "if len(t) > 0:\n",
        "  closest_recall_idx = np.argmin(np.abs(r - target_recall))\n",
        "  # Ensure the index is within bounds of t\n",
        "  thr = t[min(closest_recall_idx, len(t) - 1)]\n",
        "else:\n",
        "  thr = 0.5 # Default threshold if no thresholds are found\n",
        "\n",
        "print(\"VAL threshold for ~90% recall:\", float(thr))\n",
        "\n",
        "# --- Re-calculate test probabilities and true labels ---\n",
        "te_ds = datasets.ImageFolder(os.path.join(DATA_ROOT, \"test\"), tf_eval)\n",
        "te_loader = DataLoader(te_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "test_probs = []; test_y = []\n",
        "with torch.no_grad():\n",
        "    for x, y_true in te_loader:\n",
        "        x = x.to(device)\n",
        "        test_probs.append(model(x).softmax(1)[:, 1].cpu().numpy())\n",
        "        test_y.append(y_true.numpy())\n",
        "\n",
        "test_probs = np.concatenate(test_probs)\n",
        "test_y = np.concatenate(test_y)\n",
        "# --- End of re-calculation ---\n",
        "\n",
        "# apply threshold to test using the re-calculated test_y and test_probs\n",
        "test_preds_thr = (test_probs >= thr).astype(int)\n",
        "\n",
        "print(\"TEST @thr:\",\n",
        "      \"precision=\", precision_score(test_y, test_preds_thr, zero_division=0),\n",
        "      \"recall=\",    recall_score(test_y, test_preds_thr,  zero_division=0),\n",
        "      \"f1=\",        f1_score(test_y, test_preds_thr,      zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN22E1YqOO9V",
        "outputId": "56b1d209-3855-4fff-d68b-877a99ddb865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL threshold for ~90% recall: 0.1130559891462326\n",
            "TEST @thr: precision= 0.782703172533681 recall= 0.8982543640897755 f1= 0.8365071992568509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scan Drive for checkpoints\n",
        "import os, glob, pandas as pd\n",
        "\n",
        "hits = glob.glob(\"/content/drive/**/best.pt\", recursive=True)\n",
        "df = pd.DataFrame({\"path\": hits})\n",
        "df[\"exp_dir\"] = df[\"path\"].apply(lambda p: os.path.dirname(p))\n",
        "df[\"exp_name\"] = df[\"exp_dir\"].apply(os.path.basename)\n",
        "\n",
        "# Heuristic guesses\n",
        "def guess_arch(p):\n",
        "    p = p.lower()\n",
        "    return \"resnet50\" if \"resnet50\" in p else \"resnet18\"\n",
        "def guess_img(p):\n",
        "    p = p.lower()\n",
        "    return 384 if \"384\" in p else 224\n",
        "\n",
        "df[\"arch_guess\"] = df[\"path\"].apply(guess_arch)\n",
        "df[\"img_guess\"]  = df[\"path\"].apply(guess_img)\n",
        "\n",
        "# Show most relevant ones first (those likely synthetic: contains 'sd', 'syn', 'synfire')\n",
        "priority = df[\"path\"].str.contains(r\"(sd|syn|synfire)\", case=False, regex=True)\n",
        "df = df.sort_values([\"exp_name\", \"arch_guess\"], ascending=True)\n",
        "display(df[[\"exp_name\",\"arch_guess\",\"img_guess\",\"path\"]])\n",
        "print(\"Found\", len(df), \"checkpoints.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "BOJJu24EOuka",
        "outputId": "50f66df8-61a9-4ecc-e7e8-71a4018934a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1014606374.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  priority = df[\"path\"].str.contains(r\"(sd|syn|synfire)\", case=False, regex=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           exp_name arch_guess  img_guess  \\\n",
              "0      exp_resnet18   resnet18        224   \n",
              "1  exp_resnet50_384   resnet50        384   \n",
              "\n",
              "                                                path  \n",
              "0  /content/drive/MyDrive/dfire_colab/exp_resnet1...  \n",
              "1  /content/drive/MyDrive/dfire_colab/exp_resnet5...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6250fadf-dcb0-4e53-8d53-bc3f4987c466\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exp_name</th>\n",
              "      <th>arch_guess</th>\n",
              "      <th>img_guess</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>exp_resnet18</td>\n",
              "      <td>resnet18</td>\n",
              "      <td>224</td>\n",
              "      <td>/content/drive/MyDrive/dfire_colab/exp_resnet1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>exp_resnet50_384</td>\n",
              "      <td>resnet50</td>\n",
              "      <td>384</td>\n",
              "      <td>/content/drive/MyDrive/dfire_colab/exp_resnet5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6250fadf-dcb0-4e53-8d53-bc3f4987c466')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6250fadf-dcb0-4e53-8d53-bc3f4987c466 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6250fadf-dcb0-4e53-8d53-bc3f4987c466');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-40852abf-52dd-4099-8ac8-09193b802b51\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40852abf-52dd-4099-8ac8-09193b802b51')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-40852abf-52dd-4099-8ac8-09193b802b51 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Found\\\", len(df), \\\"checkpoints\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"exp_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"exp_resnet50_384\",\n          \"exp_resnet18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"arch_guess\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"resnet50\",\n          \"resnet18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img_guess\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 113,\n        \"min\": 224,\n        \"max\": 384,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          384,\n          224\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"/content/drive/MyDrive/dfire_colab/exp_resnet50_384/best.pt\",\n          \"/content/drive/MyDrive/dfire_colab/exp_resnet18/best.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 checkpoints.\n"
          ]
        }
      ]
    }
  ]
}